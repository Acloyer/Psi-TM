% File content starts here - NO preamble

\section{Related Work}

The Psi-TM model extends standard Turing machines with minimal introspection capabilities, where introspection depth is limited to a constant $d = O(1)$. Previous work established that Psi-TM can bypass all four classical complexity barriers with minimal introspection requirements: relativization requires $d \geq 1$, natural proofs and proof complexity require $d \geq 2$, and algebraization requires $d \geq 3$.

The fundamental question addressed in this work is whether there exists a strict hierarchy of computational power based on introspection depth:

\textbf{Main Question:} Does $\text{Psi-TM}_d \subsetneq \text{Psi-TM}_{d+1}$ hold for all $d \geq 1$?

This question has important implications for understanding the relationship between introspection depth and computational capability. A positive answer would establish that each additional level of introspection provides strictly more computational power, while a negative answer would indicate a collapse point beyond which increased introspection offers no additional advantage.

\textbf{Our Contributions:}
\begin{enumerate}
\item \textbf{Strict Hierarchy Theorem:} For each $k \geq 1$, we prove $\text{Psi-TM}_k \subsetneq \text{Psi-TM}_{k+1}$
\item \textbf{Explicit Language Construction:} We construct languages $L_k$ that separate each level
\item \textbf{Structural Depth Analysis:} We characterize the structural patterns that require depth $k+1$ introspection
\item \textbf{Collapse Threshold Investigation:} We analyze whether the hierarchy collapses at some finite $k^*$
\item \textbf{Complexity Class Implications:} We establish corresponding separations in complexity classes
\end{enumerate}

\section{Lower-Bound Toolkit}

\subsection{Introspection Depth Hierarchy}

\begin{definition}[Psi-TM d Model]
For each $d \geq 1$, a Psi-TM with introspection depth $d$ is a 7-tuple:
$$M_\Psi^d = (Q, \Sigma, \Gamma, \delta, q_0, F, \iota_d)$$
where:
\begin{itemize}
\item $(Q, \Sigma, \Gamma, \delta, q_0, F)$ is a deterministic Turing machine
\item $\iota_d: \mathrm{Config}\times \mathbb{N} \to \{0,1\}^{\le \B(d,n)}$ is the $d$-limited introspection operator
\item $\Psi_k$ denotes the range of the canonical code $C_k$ over admissible atoms of depth $\le k$
\item $d$ is a constant independent of input size
\end{itemize}
\end{definition}

\begin{definition}[Structural Depth]
For a string $w \in \Gamma^*$, the structural depth $d(w)$ is defined recursively:
\begin{itemize}
\item $d(w) = 0$ if $w$ contains no nested patterns
\item $d(w) = 1 + \max\{d(w_1), d(w_2)\}$ if $w = w_1 \circ w_2$ where $\circ$ represents a structural composition
\item $d(w) = k$ if $w$ contains $k$-level nested structural patterns
\end{itemize}
\end{definition}

\paragraph{Selectors (single semantics).} Introspective access is restricted to selectors over $y=\iota_d(\mathcal{C},n)$: $\mathrm{VIEW\_STATE}(y)$, $\mathrm{VIEW\_HEAD}(y)$, and $\mathrm{VIEW\_WIN}(y,j)$ for $j\le d$. Legacy $\texttt{INT\_*}$ names are aliases to these views.

\subsection{Complexity Classes}

\begin{definition}[Psi-P d Class]
The class $\text{Psi-P}_d$ consists of languages recognizable by Psi-TM with introspection depth $d$ in polynomial time.
\end{definition}

\begin{definition}[Psi-NP d Class]
The class $\text{Psi-NP}_d$ consists of languages with polynomial-time verifiable certificates using Psi-TM with introspection depth $d$.
\end{definition}

\begin{definition}[Psi-PSPACE d Class]
The class $\text{Psi-PSPACE}_d$ consists of languages recognizable by Psi-TM with introspection depth $d$ using polynomial space.
\end{definition}

\section{Explicit Language Constructions}
\label{sec:target-languages}

\subsection{Tree Evaluation Language}

\begin{definition}[Binary Tree Encoding]
A binary tree $T$ is encoded as a string $\text{encode}(T) \in \{0,1\}^*$ as follows:
\begin{itemize}
\item Each node is encoded as a triple $(v, l, r)$ where $v$ is the node value, $l$ is the left subtree encoding, and $r$ is the right subtree encoding
\item Leaf nodes are encoded as $(v, \varepsilon, \varepsilon)$
\item The encoding uses a prefix-free code to separate node components
\end{itemize}
\end{definition}

\begin{definition}[Tree Evaluation Language $L_k$]
For each $k \geq 1$, define $L_k$ as the set of strings $\text{encode}(T)\#1^n$ where:
\begin{itemize}
\item $T$ is a binary tree of depth exactly $k+1$
\item Leaves are labeled with bits  
\item Root evaluates to $1$ under Boolean logic (AND/OR gates at internal nodes)
\end{itemize}
\end{definition}

\begin{claim}
For each $k \geq 1$, $L_k \in \text{Psi-P}_{k+1}$.
\end{claim}

\begin{proof}
We construct a Psi-TM $M$ with introspection depth $k+1$ that recognizes L k in polynomial time.

\textbf{Algorithm:}
\begin{enumerate}
\item Parse the input to extract $\text{encode}(T)$ and $1^n$
\item Obtain $y=\iota_{k+1}(\mathcal{C},n)$ and use selectors over $\mathrm{decode}_{k+1}(y)$ to access the tree structure up to depth $k{+}1$
\item Verify that the tree has depth exactly $k+1$
\item Evaluate the tree bottom-up using the structural information
\item Accept if and only if the root evaluates to 1
\end{enumerate}

\textbf{Time Analysis:}
\begin{enumerate}
\item Parsing: $O(n)$
\item Depth verification: $O(n)$ using selectors over $\mathrm{decode}_{k+1}(y)$
\item Tree evaluation: $O(n)$ since we have complete structural information
\item Total time: $O(n)$
\end{enumerate}

Therefore, $L_k \in \text{Psi-P}_{k+1}$.
\end{proof}

\section{Main Result: Strict Hierarchy}

\subsection{Theorem A: Strict Inclusion}

\begin{theorem}[Strict Hierarchy]
\label{thm:strict-hierarchy-1}
Assumes the restricted regime (deterministic, single pass, no advice, no randomness) and uses Table~\ref{tab:iota-spec}.
For all $k \geq 1$:
$$\text{Psi-TM}_k \subsetneq \text{Psi-TM}_{k+1}$$
Equivalently:
$$\text{Psi-P}_k \subsetneq \text{Psi-P}_{k+1}$$
\end{theorem}

\begin{proof}
We prove this by showing that for each $k \geq 1$, the language $L_k$ satisfies:
$$L_k \in \text{Psi-P}_{k+1} \text{ but } L_k \notin \text{Psi-P}_k$$

\textbf{Membership in Psi-P k+1:}
This follows from the claim above.

\textbf{Non-membership in Psi-P k:}
We prove that no Psi-TM with introspection depth $k$ can recognize L k in polynomial time.

\begin{lemma}[Depth-k Limitation]
\label{lem:depth-k-limitation-1}
Assumes the restricted regime (deterministic, single pass, no advice, no randomness) and uses Table~\ref{tab:iota-spec}.
Any Psi-TM with introspection depth $k$ cannot distinguish between trees of depth $k+1$ and trees of depth $k$ in polynomial time.
\end{lemma}

\begin{proof}
\textbf{Key Insight:} Introspection depth $k$ provides access only to patterns of depth $\leq k$, but cannot access depth $k+1$ patterns.

\textbf{Detailed Proof:}
For trees $T_1$ (depth $k+1$) and $T_2$ (depth $k$):

\begin{enumerate}
\item \textbf{Tree Structure Analysis:}
  \begin{itemize}
  \item Both trees have identical node structure up to level $k$
  \item $T_1$ has additional level $k+1$ with leaf values
  \item $T_2$ terminates at level $k$ with leaf values
  \end{itemize}

\item \textbf{Selector Analysis:}
  Decoding $y=\iota_k(\mathcal{C},n)$ exposes only depth-$\le k$ tags and values; level $k{+}1$ information is not accessible to selectors.

\item \textbf{Selector Equality:}
  Since depth-$\le k$ features coincide, all selectors over $\mathrm{decode}_k(\iota_k(\mathcal{C},n))$ return identical values on $\text{encode}(T_1)$ and $\text{encode}(T_2)$

\item \textbf{Depth-k agreement:}
  Both inputs share the same depth-$k$ features; therefore selectors agree at depth $k$.

\item \textbf{Selector Equality:}
  Since depth-$\le k$ features coincide, all selectors over $\mathrm{decode}_k(\iota_k(\mathcal{C},n))$ return identical values on $\text{encode}(T_1)$ and $\text{encode}(T_2)$

\item \textbf{Machine Limitation:}
  Machine $M$ with introspection depth $k$ receives identical introspection responses for both inputs and therefore cannot distinguish between them.
\end{enumerate}

\textbf{Adversary Construction:}
For any Psi-TM $M$ with introspection depth $k$, we construct an adversary $A$ that defeats $M$:

\textbf{Adversary Strategy:}
\begin{enumerate}
\item On input $w = \text{encode}(T)\#1^n$:
  ensure that for any call $y=\iota_k(\mathcal{C},n)$, selectors over $\mathrm{decode}_k(y)$ reveal only depth-$\le k$ features (for depth $k{+}1$ inputs, the depth-$k$ projection is revealed).
\item The adversary ensures that all selectors over $\mathrm{decode}_k(\iota_k(\mathcal{C},n))$ agree on $w_1$ and $w_2$ when one has depth $k$ and the other $k{+}1$
\end{enumerate}

\textbf{Information-Theoretic Argument:}
\begin{enumerate}
\item Let $T_1$ be a tree of depth $k+1$ and $T_2$ be a tree of depth $k$
\item Both trees have identical depth-$k$ structural patterns
\item The introspection function $\iota_k$ can only access depth-$k$ information
\item Therefore, all selectors over $\mathrm{decode}_k(\iota_k(\mathcal{C},n))$ agree on $\text{encode}(T_1)$ and $\text{encode}(T_2)$
\item Machine $M$ cannot distinguish between these inputs
\item Since one input is in $L_k$ and the other is not, $M$ must err on at least one input
\end{enumerate}
\end{proof}

\textbf{Separation Proof:}
By Lemma \ref{lem:depth-k-limitation-1}, any Psi-TM with introspection depth $k$ must either:
\begin{enumerate}
\item Accept some input $w_2 \notin L_k$ (false positive), or
\item Reject some input $w_1 \in L_k$ (false negative)
\end{enumerate}

This establishes that $L_k \notin \text{Psi-P}_k$.

\textbf{Hierarchy Conclusion:}
Since $L_k \in \text{Psi-P}_{k+1}$ but $L_k \notin \text{Psi-P}_k$, we have:
$$\text{Psi-P}_k \subsetneq \text{Psi-P}_{k+1}$$

This holds for all $k \geq 1$, establishing the strict hierarchy.
\end{proof}

\subsection{Theorem B: Lower Bound on Structural Depth}

\begin{theorem}[Structural Depth Lower Bound]
\label{thm:structural-depth-lower-bound-1}
Assumes the restricted regime (deterministic, single pass, no advice, no randomness) and uses Table~\ref{tab:iota-spec}.
For any language $L \in \text{Psi-P}_{k+1} \setminus \text{Psi-P}_k$, there exists a family of inputs $\{w_n\}_{n \geq 1}$ such that:
\begin{enumerate}
\item $w_n$ has length $n$
\item $w_n$ requires structural depth $k+1$ for recognition
\item Any Psi-TM with introspection depth $k$ requires $\Omega(n^{k+1})$ time to recognize $w_n$
\end{enumerate}
\end{theorem}

\begin{proof}
We construct explicit families of inputs that demonstrate the lower bound.

\textbf{Input Family Construction:}
For each $n \geq 1$, construct $w_n$ as follows:
\begin{enumerate}
\item Start with base pattern $P_0 = 01$
\item For each level $i$ from 1 to $k+1$:
   \begin{itemize}
   \item Create pattern $P_i = P_{i-1} \circ P_{i-1}$ where $\circ$ represents structural composition
   \item $P_i$ has structural depth $i$
   \end{itemize}
\item $w_n = P_{k+1}$ repeated to achieve length $n$
\end{enumerate}

\textbf{Structural Depth Analysis:}
\begin{enumerate}
\item $P_0$ has depth 0 (no nested patterns)
\item $P_1 = P_0 \circ P_0$ has depth 1
\item $P_2 = P_1 \circ P_1$ has depth 2
\item $\vdots$
\item $P_{k+1}$ has depth $k+1$
\end{enumerate}

\textbf{Lower Bound Proof:}
Any Psi-TM with introspection depth $k$ must:

\begin{enumerate}
\item \textbf{Pattern Analysis:} Process $w_n$ by examining depth-$k$ patterns only
\item \textbf{Information Limitation:} Cannot access the depth $k+1$ structural information
\item \textbf{Exhaustive Search Requirement:} Must check all possible depth-$k$ decompositions
\end{enumerate}

\textbf{Complexity Analysis:}
For trees with $n$ nodes and depth $k+1$:

\begin{enumerate}
\item \textbf{Leaf Count at Level k+1:} $2^k$ leaves at level $k+1$
\item \textbf{Possible Configurations:} Each leaf can be 0 or 1, giving $2^{2^k}$ possible configurations
\item \textbf{Tree Size Relationship:} For trees with $n$ nodes, $2^k = \Theta(n^{1/(k+1)})$
\item \textbf{Required Checks:} Machine must check $2^{\Theta(n^{1/(k+1)})}$ possible configurations
\item \textbf{Time Complexity:} Each check requires $\Omega(n)$ time for pattern matching
\item \textbf{Total Time:} $\Omega(n \cdot 2^{\Theta(n^{1/(k+1)})}) = \Omega(n^{k+1})$
\end{enumerate}

\textbf{Formal Justification:}
\begin{align*}
\text{Number of leaves at level } k+1 &= 2^k \\
\text{Possible configurations} &= 2^{2^k} \\
\text{For trees with } n \text{ nodes: } 2^k &= \Theta(n^{1/(k+1)}) \\
\text{Required checks} &= 2^{\Theta(n^{1/(k+1)})} \\
\text{Time per check} &= \Omega(n) \\
\text{Total time} &= \Omega(n \cdot 2^{\Theta(n^{1/(k+1)})}) = \Omega(n^{k+1})
\end{align*}

\textbf{Upper Bound:}
A Psi-TM with introspection depth $k+1$ can recognize $w_n$ in $O(n)$ time by directly accessing the depth $k+1$ pattern.

This establishes the $\Omega(n^{k+1})$ lower bound for depth-$k$ machines.
\end{proof}

\section{Adversary Arguments}

\subsection{Formal Adversary Construction}

\begin{theorem}[Adversary Lower Bound]
\label{thm:adversary-lower-bound-1}
Assumes the restricted regime (deterministic, single pass, no advice, no randomness) and uses Table~\ref{tab:iota-spec}.
For any Psi-TM $M$ with introspection depth $k$, there exists an adversary $A$ such that:
$M$ cannot solve $L_k$ against $A$.
\end{theorem}

\begin{proof}
We construct an explicit adversary strategy that defeats any depth-$k$ Psi-TM.

\textbf{Adversary Strategy:}
\begin{enumerate}
\item \textbf{Input Generation:} For each $n \geq 1$, the adversary generates two inputs:
  \begin{itemize}
  \item $w_1 = \text{encode}(T_1)\#1^n$ where $T_1$ has depth $k+1$ and evaluates to 1
  \item $w_2 = \text{encode}(T_2)\#1^n$ where $T_2$ has depth $k$ and evaluates to 0
  \end{itemize}

\item \textbf{Introspection Response:} When $M$ calls $\texttt{INT\_PATTERN(k)}$ on input $w$:
  \begin{itemize}
  \item If $w$ has depth $k$: Return actual depth-$k$ patterns
  \item If $w$ has depth $k+1$: Return only the depth-$k$ projection
  \end{itemize}

\item \textbf{Consistency Maintenance:} The adversary ensures that:
All selectors over $\mathrm{decode}_k(\iota_k(\mathcal{C},n))$ agree on $w_1$ and $w_2$
\end{enumerate}

\textbf{Information-Theoretic Analysis:}
\begin{enumerate}
\item The introspection function $\iota_k$ can only access depth-$k$ information
\item Both inputs $w_1$ and $w_2$ have identical depth-$k$ structural patterns
\item Machine $M$ receives identical introspection responses for both inputs
\item Therefore, $M$ must produce the same output for both inputs
\item Since $w_1 \in L_k$ and $w_2 \notin L_k$, $M$ must err on at least one input
\end{enumerate}

\textbf{Error Probability:}
The adversary can generate inputs such that $M$ errs with probability at least $1/2$ by ensuring that the machine cannot distinguish between valid and invalid inputs based solely on depth-$k$ information.

This establishes that no depth-$k$ Psi-TM can solve $L_k$ against this adversary.
\end{proof}

\section{Complexity Class Implications}

\subsection{Class Separations}

\begin{theorem}[Complexity Class Separations]
Assumes the restricted regime (deterministic, single pass, no advice, no randomness) and uses Table~\ref{tab:iota-spec}.
For all $k \geq 1$:
$$\text{Psi-P}_k \subsetneq \text{Psi-P}_{k+1} \subsetneq \text{PSPACE}$$
$$\text{Psi-NP}_k \subsetneq \text{Psi-NP}_{k+1} \subsetneq \text{NPSPACE}$$
$$\text{Psi-PSPACE}_k \subsetneq \text{Psi-PSPACE}_{k+1} \subsetneq \text{EXPSPACE}$$
\end{theorem}

\begin{proof}
\textbf{Strict Inclusions:}
Follow from the main hierarchy theorem and the explicit language constructions.

\textbf{PSPACE Inclusions:}
Any Psi-TM with constant introspection depth can be simulated by a standard Turing machine with polynomial space overhead, as shown in the formal definition document.

\textbf{Proper Inclusions:}
The languages $L_k$ demonstrate that the inclusions are proper, as they belong to higher levels but not to lower levels of the hierarchy.
\end{proof}

\subsection{Collapse Threshold Analysis}

\begin{theorem}[No Finite Collapse]
Assumes the restricted regime (deterministic, single pass, no advice, no randomness) and uses Table~\ref{tab:iota-spec}.
The Psi-TM hierarchy does not collapse at any finite level $k^*$.
\end{theorem}

\begin{proof}
For any finite $k^*$, we can construct a language $L_{k^*+1}$ that requires depth $k^*+1$ introspection but cannot be recognized by any depth-$k^*$ Psi-TM.

This follows from the explicit construction of $L_k$ for each $k \geq 1$ and the adversary arguments that show the impossibility of depth-$k$ machines recognizing depth-$(k+1)$ languages.
\end{proof}

\section{Algorithmic Results}

\subsection{Efficient Simulation}

\begin{theorem}[Efficient Psi-TM Simulation]
Assumes the restricted regime (deterministic, single pass, no advice, no randomness) and uses Table~\ref{tab:iota-spec}.
Any Psi-TM $M_{psi}$ with d-limited introspection can be simulated by a standard Turing machine $M$ with slowdown $O(n^3 \cdot f(d))$, where $f$ is a polynomial function.
\end{theorem}

\begin{proof}
We present an algorithm for simulating $M_{psi}$:

\begin{figure}[ht]
\framebox[\textwidth]{\begin{minipage}{0.95\textwidth}
\textbf{Algorithm:} Psi-TM Simulation
\begin{enumerate}
\item Initialize state $(q_0, \varepsilon, \varepsilon, \emptyset)$
\item \textbf{while} not in accepting or rejecting state \textbf{do}
  \begin{enumerate}
  \item Read current symbol $a$
  \item Compute the required selectors from $y=\iota_d(\mathcal{C},n)$
  \item Apply transition $\delta(q, a, \psi) = (q', b, d)$
  \item Update configuration
  \item Move head according to $d$
  \end{enumerate}
\end{enumerate}
\end{minipage}}
\end{figure}

Each introspection call takes $O(n^3)$ time by the structural depth computation algorithm. Total simulation time: $O(T(n) \cdot n^3 \cdot f(d))$.
\end{proof}

\subsection{Universal Psi-TM}

\begin{theorem}[Existence of Universal Psi-TM]
Assumes the restricted regime (deterministic, single pass, no advice, no randomness) and uses Table~\ref{tab:iota-spec}.
There exists a universal Psi-TM $U_{psi}$ with d-limited introspection that can simulate any Psi-TM $M_{psi}$ with d-limited introspection with polynomial slowdown.
\end{theorem}

\begin{proof}
We construct $U_{psi}$ as follows:

\begin{enumerate}
\item \textbf{Encoding}: $U_{psi}$ takes as input a description of $M_{psi}$ and input string $x$
\item \textbf{Simulation}: $U_{psi}$ maintains the configuration of $M_{psi}$ on its tape
\item \textbf{Introspection}: For each introspection call of $M_{psi}$, $U_{psi}$ computes the same introspection
\item \textbf{Transitions}: $U_{psi}$ applies the transition function of $M_{psi}$ based on the encoded description
\end{enumerate}

Since both machines have d-limited introspection, the simulation preserves the introspection constraints. The slowdown is polynomial due to the overhead of interpreting the encoded machine description and computing introspection calls.
\end{proof}

\section{Outlook â€” Hierarchy}

We have established a strict hierarchy of Psi-TM models based on introspection depth, with the following key results:

\begin{enumerate}
\item \textbf{Strict Hierarchy}: For each $k \geq 1$, $\text{Psi-TM}_k \subsetneq \text{Psi-TM}_{k+1}$
\item \textbf{Explicit Constructions}: We provided concrete language constructions $L_k$ that separate each level
\item \textbf{Adversary Arguments}: We constructed formal adversaries that demonstrate the impossibility of depth-$k$ machines recognizing depth-$(k+1)$ languages
\item \textbf{Complexity Implications}: We established corresponding separations in complexity classes
\item \textbf{No Collapse}: We proved that the hierarchy does not collapse at any finite level
\end{enumerate}

These results provide a rigorous foundation for understanding the relationship between introspection depth and computational power in the Psi-TM model, opening new directions in computational complexity theory and formal automata theory.

% End of included content