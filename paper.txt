   Psi-TM: Minimal Introspection for Complexity Barrier Analysis
          A Conservative Mathematical Foundation for Introspective Computation

                                          Rafig Huseynzade
                                         University of Alberta
                                      huseynzaderafig@gmail.com

                                             August 29, 2025


                                                  Abstract
          We introduce Psi-TM (Ψ-TM), a computational model that extends Structurally-Aware Turing
      Machines with minimal constant-depth introspection d = O(1). We present an oracle-relative
      separation and a conservative barrier status: relativization (proven), natural proofs and proof
      complexity (partial/conditional), algebraization (open/conservative). Our main result establishes
      PΨOΨ ̸= N PΨOΨ for a specifically constructed oracle OΨ .
          We analyze minimal introspection requirements (d = 1, 2, 3) with oracle-relative strictness;
      d = 3 is a plausible target subject to algebraization; unrelativized sufficiency remains open. This
      frames barrier progress conservatively while maintaining selectors-only semantics and explicit
      information-budget accounting.


Contents
1 Introduction                                                                                              5

2 Formal Definition of Structural Depth                                                                      5
  2.1 Binary Tree Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .             5
  2.2 Formal Structural Depth Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . .             5

3 Formal Definition of Psi-TM                                                                                7
  3.1 Basic Components . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .             7
  3.2 Formal Introspection Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .             7
  3.3 Transition Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .          7
  3.4 Introspection Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .            7
  3.5 Introspection Interface ιj (Model Freeze) . . . . . . . . . . . . . . . . . . . . . . . . .            8

4 Information-Theoretic Limitations                                                                          8

5 Basic Properties of Psi-TM                                                                                 8
  5.1 Equivalence to Standard Turing Machines . . . . . . . . . . . . . . . . . . . . . . . .                8
  5.2 Barrier status (conservative) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .          9
  5.3 Minimality of Introspection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .           10

6 Complexity Classes                                                                                        10

7 Outlook — Model Freeze                                                                                    11


                                                      1
8 Lower-Bound Tools                                                                               11
  8.1 Worked Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
      8.1.1 Example Application . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
      8.1.2 Example Application (Average-Case) . . . . . . . . . . . . . . . . . . . . . . . 13
      8.1.3 Example Application (High-Depth Case) . . . . . . . . . . . . . . . . . . . . . 13

9 Target Language Lk (Pointer-Chase)                                                                14

10 Target Language Lphase
                    k     (Phase-Locked Access)                                                     17

11 Anti-Simulation Hook                                                                             20

12 Related Work                                                                                     22

13 Formal Definitions                                                                               23
   13.1 Complexity Barriers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
   13.2 Psi-TM barrier status . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

14 Relativization Barrier: k >= 1                                                                   23

15 Natural Proofs Barrier: k >= 2                                                                   24

16 Proof Complexity Barrier: k >= 2                                                                 24

17 Algebraization Barrier: k >= 3                                                                   25

18 Barrier Hierarchy                                                                                25

19 Optimal Introspection Depth                                                                      26

20 Complexity Class Implications                                                                    26

21 Outlook — Barriers                                                                               27

22 Related Work                                                                                     27

23 Lower-Bound Toolkit                                                                               28
   23.1 Introspection Depth Hierarchy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
   23.2 Complexity Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28

24 Explicit Language Constructions                                                                 28
   24.1 Tree Evaluation Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28

25 Main Result: Strict Hierarchy                                                                    29
   25.1 Theorem A: Strict Inclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
   25.2 Theorem B: Lower Bound on Structural Depth . . . . . . . . . . . . . . . . . . . . . 31

26 Adversary Arguments                                                                            32
   26.1 Formal Adversary Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32




                                                  2
27 Complexity Class Implications                                                                      33
   27.1 Class Separations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
   27.2 Collapse Threshold Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34

28 Algorithmic Results                                                                                 34
   28.1 Efficient Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
   28.2 Universal Psi-TM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34

29 Outlook — Hierarchy                                                                                35

30 Outlook — STOC/FOCS Synthesis                                                                      35

31 Preliminaries                                                                                     36
   31.1 Structural Depth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
   31.2 Psi-TM Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
   31.3 Complexity Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

32 Explicit Language Constructions                                                                 37
   32.1 Tree Evaluation Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

33 Main Result: Strict Hierarchy                                                                      38

34 Adversary Arguments                                                                            40
   34.1 Formal Adversary Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

35 Complexity Class Implications                                                                      41
   35.1 Class Separations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
   35.2 Barrier status hierarchy (oracle-relative / conservative) . . . . . . . . . . . . . . . . . 41

36 Algorithmic Results                                                                                 41
   36.1 Efficient Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
   36.2 Universal Psi-TM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

37 Lower Bounds                                                                                42
   37.1 Time Complexity Lower Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

38 Outlook — Adversary Results                                                                        44

39 Formal Definitions and Preliminaries                                                            44
   39.1 Structural Pattern Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
   39.2 Formal Introspection Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44

40 Information-Theoretic Limitations                                                                  45

41 Main Theoretical Results                                                                           45
   41.1 Complexity Class Hierarchy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
   41.2 Connection to Classical Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
   41.3 Strict Inclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46




                                                   3
42 Algorithmic Results                                                                                 46
   42.1 Efficient Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
   42.2 Universal Psi-TM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

43 Complexity Barriers                                                                              47
   43.1 Time bounds (conservative) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
   43.2 Space bounds (conservative) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

44 Adversary Arguments                                                                            48
   44.1 Formal Adversary Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

45 Outlook — Theoretical Results                                                                     49
   45.1 Controlled Relaxations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

46 Independent Platforms                                                                                50
   46.1 Psi-decision trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
   46.2 IC-circuits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

47 Bridges with Explicit Losses                                                                        51

48 Methods                                                                                             52

49 Pre-Release Hardening: Stress Tests and Adversarial Outcomes                                       52
   49.1 Stress Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
   49.2 Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53

50 Appendix: Zero-Risk Map                                                                             53

51 Open Problems and Research Directions                                                              53
   51.1 Fractional k values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
   51.2 Quantum Psi-TM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
   51.3 Average-case complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
   51.4 Circuit complexity extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
   51.5 Interactive proof systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

52 Conclusion                                                                                          54




                                                    4
Remark 0.1 (Notation). We write logarithms with explicit base: e.g., log2 n. Unless stated
otherwise, all logarithms are base 2.


1     Introduction
In this work, we formally define the computational model Psi-TM (Psi-Turing Machine) as a contin-
uation of the Structurally-Aware Turing Machines (SA-TM) [50] concept with minimal introspection.
The Psi-TM model is characterized by selectors-only introspection semantics and explicit information
budgets. Barrier statements are conservative: oracle-relative where proved, partial/conditional
otherwise.


2     Formal Definition of Structural Depth
2.1    Binary Tree Representation
Definition 2.1 (Binary Tree). A binary tree T is a finite tree where each node has at most two
children. We denote:

    • root(T ) – the root node of T

    • left(v) – the left child of node v (if exists)

    • right(v) – the right child of node v (if exists)

    • leaf(T ) – the set of leaf nodes in T

    • depth(v) – the depth of node v (distance from root)

    • depth(T ) = maxv∈T depth(v) – the depth of tree T

Definition 2.2 (Parsing Tree). For a string w ∈ {0, 1}∗ , a parsing tree Tw is a binary tree where:

    • Each leaf is labeled with a symbol from {0, 1}

    • Each internal node represents a structural composition

    • The concatenation of leaf labels in left-to-right order equals w

2.2    Formal Structural Depth Definition
Definition 2.3 (Formal Structural Depth). For a string w ∈ {0, 1}∗ , the structural depth d(w) is
defined as:
                                   d(w) = min depth(Tw )
                                                   Tw

where the minimum is taken over all possible parsing trees Tw for w.
   Base cases:

    • d(ε) = 0 (empty string)

    • d(0) = d(1) = 0 (single symbols)

   Recursive case: For |w| > 1, d(w) = minw=uv {1 + max(d(u), d(v))} where the minimum is
taken over all binary partitions of w.

                                                       5
Lemma 2.4 (Well-Definedness of Structural Depth). The structural depth function d : {0, 1}∗ → N
is well-defined and computable.

Proof. Well-Definedness:

  1. For strings of length ≤ 1, d(w) is explicitly defined

  2. For longer strings, the minimum exists because:

       • The set of possible partitions is finite (at most n − 1 partitions for length n)
       • Each partition yields a finite depth value
       • The minimum of a finite set of natural numbers exists

    Computability: We provide a dynamic programming algorithm. The algorithm is presented
below.
    Correctness:

  1. Base cases are handled correctly

  2. For each substring w[i : j], we try all possible binary partitions

  3. The algorithm computes the minimum depth over all parsing trees

  4. Time complexity: O(n3 ) due to three nested loops



  Algorithm: Structural Depth Computation

     1. Input: String w = w1 w2 . . . wn

     2. Output: Structural depth d(w)

     3. Initialize dp[i][j] = 0 for all i ≤ j

     4. for i = 1 to n do

         (a) dp[i][i] = 0    // Base case: single symbols

     5. for len = 2 to n do

         (a) for i = 1 to n − len + 1 do
                i. j = i + len − 1
               ii. dp[i][j] = ∞
              iii. for k = i to j − 1 do
                   A. dp[i][j] = min(dp[i][j], 1 + max(dp[i][k], dp[k + 1][j]))

     6. return dp[1][n]




                                                   6
3     Formal Definition of Psi-TM
3.1      Basic Components
Definition 3.1 (Psi-TM Alphabet). Let Σ be a finite alphabet, Γ = Σ ∪ {B} be the extended
alphabet, where B is the blank symbol. The set of states Q = Qstd ∪ Qpsi , where:

    • Qstd – standard Turing machine states

    • Qpsi – introspective states with limited access to structure

Definition 3.2 (Psi-TM Configuration). A configuration C of a Psi-TM is a tuple:

                                           C = (q, α, β, ψ)

where:

    • q ∈ Q – current state

    • α ∈ Γ∗ – tape content to the left of the head

    • β ∈ Γ∗ – tape content to the right of the head

    • ψ ∈ Ψd – introspective state, where Ψd is the set of introspective metadata of depth ≤ d

3.2      Formal Introspection Functions
Selectors as views over ιd . All introspective access is via y = ιd (C, n) and selectors
VIEW_STATE(y), VIEW_HEAD(y), and VIEW_WIN(y, d′ ) applied to decoded (y). Any legacy
INT_* notation is an alias for a selector over decoded (ιd (C, n)).

3.3      Transition Function
Definition 3.3 (Psi-TM Transition Function). The transition function δ : Q × Γ × Ψd → Q × Γ ×
{L, R, S} is defined as:
                                    δ(q, a, ψ) = (q ′ , b, d)
where:

    • q, q ′ ∈ Q

    • a, b ∈ Γ

    • d ∈ {L, R, S} – head movement direction

    • ψ ∈ Ψd – current introspective metadata

3.4      Introspection Constraints
Definition 3.4 (d-Limited Introspection). For a configuration C on an input of length n, a single
introspection call yields the codeword y = ιd (C, n). Its length is bounded by B(d, n) and decoded (y)
exposes only depth-≤ d tags (Lemma 8.2).




                                                  7
Table 1: Interface specification for ιj (single source of truth). Complete definition of inputs, outputs,
per-step bit budget B(d, n) = c · d · log2 n, call placement constraints, and transcript accounting. All
lemmas and theorems reference this specification rather than duplicating it.
        Field                    Specification
        Depth index              j ∈ {1, . . . , d}
        Per-step bit budget      B(d, n) = c · d · log2 n with fixed c ≥ 1
        Call policy              Exactly once per computation step; payload injected into δ that
                                 step
        Inputs                   Current state and allowed local view; no advice; no randomness
        Output payload           Bitstring y ∈ {0, 1}≤B(d,n)
        Transcript accounting    Over T steps: at most T · B(d, n) bits exposed via ι; at most
                                 2T ·B(d,n) distinct transcripts


3.5   Introspection Interface ιj (Model Freeze)
Remark 3.5 (Depth notation). We use d as the global depth bound. Interface indexes are
j ∈ {1, . . . , d}, and the per-step budget is B(d, n) = c · d · log2 n with fixed c ≥ 1.
Definition 3.6 (Iota injection into the transition). Let Ct be the configuration at step t. Exactly
once per step, the machine obtains a payload yt = ιj (Ct , n) ∈ {0, 1}≤B(d,n) and passes it as an
auxiliary argument to the transition:
                                    (qt+1 , st+1 ) = δ qt , st , xt ; yt .
                                                                       

Transcript accounting therefore sums to at most T · B(d, n) bits over T steps.

Restricted Regime. Unless stated otherwise, all results assume: deterministic; single pass over
input; no advice; no randomness. We refer to Table 1 whenever ιj is used and write B(d, n) as
specified above.


4     Information-Theoretic Limitations
Lemma 4.1 (Selector indistinguishability at depth d). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. For any d, there exist inputs x, x′ with
structural depths d and d+1 such that for the same configuration C on inputs of length n, every
selector over decoded (ιd (C, n)) returns identical outputs on x and x′ within one step.
Proof sketch. By the interface in Table 1, the decoded codeword at depth d exposes only depth-≤ d
tags. Choose inputs that are identical on all depth-≤ d local features but differ only in depth-(d+1)
structure. Then all selectors over decoded (ιd (C, n)) coincide on the two inputs. Moreover, by
Lemma 8.2, each step reveals at most B(d, n) bits, which does not permit recovery of depth-(d+1)
features at depth d in one step.


5     Basic Properties of Psi-TM
5.1   Equivalence to Standard Turing Machines
Theorem 5.1 (Computational Equivalence). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. For any standard Turing machine M , there
exists an equivalent Psi-TM Mpsi with d-limited introspection, where d = O(1).

                                                      8
Proof. Let M = (Q, Σ, Γ, δ, q0 , qaccept , qreject ) be a standard Turing machine.
   We construct Mpsi = (Qpsi , Σ, Γ, δpsi , q0 , qaccept , qreject , ιd ) as follows:

   1. Qpsi = Q ∪ Qpsi , where Qpsi = ∅ initially

   2. No introspection is used (no calls to ιd )

   3. δpsi (q, a, ∅) = δ(q, a) for all q ∈ Qstd

   Simulation Verification: Mpsi simulates M step-by-step because introspection is not used in
standard states, and the transition function δpsi reduces to δ when ψ = ∅.
   Reverse Simulation: Any Psi-TM can be simulated by a standard Turing machine by explicitly
encoding introspective metadata in the state. The size of ψ is bounded by f (d) · n = O(n) for
constant d, so the simulation requires polynomial overhead.

5.2    Barrier status (conservative)
Theorem 5.2 (Conservative barrier statements). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. There exist oracle-relative separations and
partial/conditional results consistent with the barrier status in the barrier analysis section:

   1. Oracle-relative: PΨOΨ ̸= N PΨOΨ for a suitable oracle OΨ (Theorem 5.3)

   2. Partial/conditional: statements for natural proofs and proof complexity; algebraization
      open/conservative

Proof. Consider the Structural Pattern Recognition (SPR) problem:
     Definition of SPR: Given a string w ∈ {0, 1}∗ , determine if d(w) ≤ d.
     Standard TM Complexity: For standard Turing machines, this requires Ω(nd ) time, as it is
necessary to track d levels of nesting by explicit computation.
     Psi-TM Solution (selectors-only): For Psi-TM with d-limited introspection, obtain y =
ιd (C, n) and use selectors over decoded (y) to read bounded-depth summaries; all accesses obey the
budget in Lemma 8.2.
     Time Analysis:

   1. INT_STRUCT(d)(w) computation: O(n3 ) by the dynamic programming algorithm

   2. Pattern checking: O(n) since d = O(1)

   3. Total time: O(n3 )

   Thus, SPR ∈ Psi-Pd for Psi-TM, but requires Ω(nd ) time for standard Turing machines (under
standard complexity assumptions).

Theorem 5.3 (Diagonal Separation for Psi-TM). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. There exists an oracle OΨ such that
PΨOΨ ̸= N PΨOΨ .




                                                      9
5.3    Minimality of Introspection
Theorem 5.4 (Minimality of Introspection). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. If Psi-TM introspection is limited to a constant
d = O(1), then the model preserves equivalence to standard Turing machines in computational power.
Proof. Let Mpsi be a Psi-TM with d-limited introspection, where d = O(1).
   We show that Mpsi can be simulated by a standard Turing machine M with polynomial slowdown:
    1. State of M encodes: (q, α, β, ψ)
    2. Size of ψ is bounded by f (d) · n = O(n) for constant d
    3. Each introspection call y = ιd (C, n) is computed explicitly in O(n3 ) time
    4. Each step of Mpsi is simulated in O(n3 ) steps of M
    5. Total simulation time: O(T (n) · n3 ), where T (n) is the running time of Mpsi
    Reverse Simulation: Any standard Turing machine can be simulated by a Psi-TM with empty
introspection without slowdown.
    This establishes polynomial-time equivalence between Psi-TM with constant introspection depth
and standard Turing machines.


6     Complexity Classes
Definition 6.1 (Psi-P Class). The class Psi-Pd consists of languages recognizable by Psi-TM with
d-limited introspection in polynomial time.
Definition 6.2 (Psi-NP Class). The class Psi-NPd consists of languages with polynomial-time
verifiable certificates using Psi-TM with d-limited introspection.
Definition 6.3 (Psi-PSPACE Class). The class Psi-PSPACEd consists of languages recognizable by
Psi-TM with d-limited introspection using polynomial space.
Theorem 6.4 (Class Hierarchy). For any d1 < d2 = O(1):
                                     Psi-Pd1 ⊆ Psi-Pd2 ⊆ PSPACE
                                  Psi-NPd1 ⊆ Psi-NPd2 ⊆ NPSPACE
                           Psi-PSPACEd1 ⊆ Psi-PSPACEd2 ⊆ EXPSPACE
Proof. Inclusion Proof: Let L ∈ Psi-Pd1 . Then there exists a Psi-TM M with d1 -limited intro-
spection that recognizes L in polynomial time.
   We construct a Psi-TM M ′ with d2 -limited introspection:
    1. M ′ simulates M step-by-step
    2. For each introspection call of M , M ′ performs the same introspection
    3. Since d1 < d2 , all introspection calls of M are valid for M ′
    4. Time complexity remains polynomial
   PSPACE Inclusion: Any Psi-TM with constant introspection depth can be simulated by a
standard Turing machine with polynomial space overhead, as shown in the minimality theorem.
   The same arguments apply to NP and PSPACE classes.

                                                    10
7     Outlook — Model Freeze
The Psi-TM model represents a rigorous mathematical foundation for a minimal introspective
computational model that:

    1. Preserves equivalence to standard Turing machines

    2. Provides partial bypass of complexity barriers

    3. Minimizes introspection to constant depth

    4. Formally establishes structural depth as a computable property

    5. Provides explicit constructions for information-theoretic limitations

   This model opens new directions in computational complexity theory and formal automata
theory.


8     Lower-Bound Tools
Remark 8.1 (Preconditions for This Section). All results in this section assume the restricted
regime: deterministic computation, single pass over input, no advice strings, no randomness. All
introspection functions ιd follow the specification in Table 1 with fixed parameter c ≥ 1 throughout.

    These three fundamental tools constitute the core methodology for establishing lower bounds
in the restricted regime. The Budget Lemma provides a basic counting argument for transcript
limitations. The Ψ-Fooling Bound extends this to worst-case distinguishability, while the Ψ-Fano
Bound handles average-case scenarios with error tolerance. Together, they form the foundation for
proving separations in subsequent target languages.

Lemma 8.2 (Budget Lemma). Assumes the restricted regime (deterministic, single pass, no advice,
no randomness) and uses Table 1. For any Psi-TM with introspection depth d ≥ 1, running for
T ≥ 1 steps on input of length n ≥ 1, where the introspection function ιd (Table 1) exposes at most
B(d, n) = c · d · log2 n bits per step with fixed parameter c ≥ 1:

                              Number of distinct transcripts ≤ 2 T · B(d,n)                               (1)

This bound is tight in the worst case.

Proof sketch. A transcript is the sequence (y1 , y2 , . . . , yT ) where yt = ιd (Ct , n) is the introspection
output at step t and Ct is the machine configuration. Each step exposes at most B(d, n) bits via
ιd . Over T steps, total information ≤ T · B(d, n) bits. Number of possible transcript sequences
≤ 2T ·B(d,n) .
     Tightness: This bound is achieved when ιd outputs the maximum allowed payload at each step.
For example, consider the introspection function:

                ιd (Ct , n) = encode(step_number(t) ∥ head_position(Ct ) ∥ state(Ct ))

where the encoding uses exactly B(d, n) bits by padding or truncating as needed. Over T steps, this
produces 2T ·B(d,n) distinct transcript sequences when the machine visits 2B(d,n) different configurations
per step.
   This differs from classical transcript counting by the explicit B(d, n) constraint from Table 1.

                                                     11
Lemma 8.3 (Ψ-Fooling Bound). Assumes the restricted regime and uses Table 1. For any deter-
ministic Psi-TM with introspection depth ≤ d, input length n ≥ 1, running time T ≥ 1, and fooling
set Fn with |Fn | = M ≥ 2 pairwise distinguishable inputs, where introspection function ιd (Table 1)
provides at most B(d, n) = c · d · log2 n bits per step:
                                                      log2 M
                                                               
                                            T ≥                                                  (2)
                                                      B(d, n)
Theorem 8.4 (Ψ-Fooling Bound). The statement is identical to Lemma 8.3 with the same precondi-
tions and conclusion T ≥ ⌈log2 M/B(d, n)⌉.
Proof sketch. By Lemma 8.2, after T steps there are at most 2T ·B(d,n) distinct transcripts. To
distinguish M inputs in the fooling set, require 2T ·B(d,n) ≥ M , hence T · B(d, n) ≥ log2 M and the
bound follows by ceiling. Classical fooling arguments use unlimited communication; here the channel
capacity is bounded by B(d, n) bits per step.

Lemma 8.5 (Ψ-Fano Bound). Assumes the restricted regime and uses Table 1. For any Psi-TM
with introspection depth ≤ d, input length n ≥ 1, running time T ≥ 1, input distribution over M ≥ 2
outcomes, and error probability 0 < ε < 1 − 1/M , where introspection function ιd (Table 1) provides
channel capacity T · B(d, n) bits with B(d, n) = c · d · log2 n:
                                       log2 M − h(ε) − ε log2 (M − 1)
                                T ≥                                                              (3)
                                                  B(d, n)
where h(ε) = −ε log2 ε − (1 − ε) log2 (1 − ε) is the binary entropy.
Proof sketch. Standard Fano’s inequality applies to transcript information with mutual information
measured in bits. This follows the standard form of Fano’s inequality: H(X | Y ) ≤ h(ε) +
ε log2 (|X| − 1) where X is the input distribution and Y is the observed transcript. The machine
observes ≤ T · B(d, n) bits total, providing channel capacity T · B(d, n). Hence T · B(d, n) must be
at least log2 M − h(ε) − ε log2 (M − 1). Classical Fano’s inequality uses arbitrary channel capacity;
here adapted to the B(d, n) constraint specific to Ψ-TM with introspection depth d.

8.1     Worked Examples
8.1.1    Example Application
The following illustrates Lemma 8.3 in action.
   Consider depth d = 2, input length n = 1000, with fixed parameter c = 1 throughout. Thus
B(2, 1000) = 1 · 2 · log2 1000 ≈ 2 · 10 = 20 bits per step.
   For a fooling set of size M = 2100 (i.e., |Fn | = 2100 ): by equation (2),
                                           log2 M    100
                                                            
                                 T ≥               =     = 5 steps
                                           B(d, n)   20
   This demonstrates that any depth-2 Ψ-TM requires at least 5 computation steps to distinguish
between 2100 carefully constructed inputs, regardless of algorithmic sophistication.
Remark 8.6 (Dependency Structure). These tools form a hierarchy of increasing specificity:
   • Budget Lemma → fundamental counting (base for all arguments)
   • Ψ-Fooling Bound → worst-case distinguishability (enables UB/LB proofs)
   • Ψ-Fano Bound → average-case information theory (handles probabilistic scenarios)

                                                      12
8.1.2   Example Application (Average-Case)
The following illustrates Lemma 8.5 for average-case analysis.
    Consider the same parameters: depth d = 2, input length n = 1000, so B(2, 1000) = 20 bits per
step.
    Suppose we have a uniform distribution over M = 260 possible inputs, and we want error
probability ε = 0.1 (10% error rate). The binary entropy is:

                        h(0.1) = −0.1 log2 (0.1) − 0.9 log2 (0.9) ≈ 0.469 bits

   By Lemma 8.5:

                                    log2 M − h(ε) − ε log2 (M − 1)
                                 T ≥                                                             (4)
                                                B(d, n)
                                    60 − 0.469 − 0.1 · 60
                                  ≥                                                              (5)
                                             20
                                    60 − 0.469 − 6     53.531
                                  ≥                =          ≈ 2.68                             (6)
                                          20             20
    Therefore T ≥ 3 steps. This shows that even allowing 10% error rate, any depth-2 Ψ-TM
needs at least 3 steps to distinguish inputs from this distribution, demonstrating the power of
information-theoretic arguments in average-case scenarios.

8.1.3   Example Application (High-Depth Case)
Consider higher depth d = 3, larger input n = 220 = 1,048,576, with c = 1. Thus B(3, 220 ) =
3 · log2 (220 ) = 3 · 20 = 60 bits per step.
     For fooling set M = 2900 :
                                                 900
                                                    
                                           T ≥         = 15 steps                         (7)
                                                 60
    This demonstrates scalability: even with a significantly higher introspection budget (60 vs 20
bits), a proportionally larger fooling set still forces meaningful time complexity.

                   Remark 8.7 (Comparison: Worst-Case vs Average-Case).
                                 12
                                                                Fooling
                                 10                              Fano

                                  8
                                  6
                             T




                                  4
                                  2
                                  0
                                      40   80   120    160    200         240
                                                  log2 M
Compare the two approaches:

• Fooling set: M = 2100 ⇒ T ≥ 5 steps (worst-case)

• Fano bound: M = 260 , ε = 0.1 ⇒ T ≥ 3 steps (average-case)

The Fano bound trades input complexity for error tolerance, typically yielding weaker but more
general bounds.

                                                 13
      Table 2: Summary of Lower-Bound Tools (assumes restricted regime & Table 1 budget)
                                            Key Formula: B(d, n) = c · d · log2 n
    Lemma           Statement                                               Proof Idea                 Usage
    Budget Lemma    ≤ 2T ·B(d,n) transcripts                                Counting argument          All target languages
    Ψ-Fooling       T ≥ ⌈log M/B(d, n)⌉                                     Distinguishability         Pointer-chase Lk
    Bound
    Ψ-Fano Bound    T ≥ [log2 M − h(ε) − ε log2 (M −                        Fano’s inequality          Average-case analysis
                    1)]/B(d, n)


Remark 8.8 (Visualization). Figure 1 shows the linear relationship between transcript requirements
T and fooling set size log |Fn | for different budget constraints B(d, n).

                                               Lower Bound: T ≥ log2 |Fn |/B(d, n)

                                               d = 1: B(1, 1000) = 10
                                   10
                                               d = 2: B(2, 1000) = 20
                                               d = 3: B(3, 1000) = 30
                       T (steps)




                                   5



                                   0
                                        0       20       40       60          80         100    120
                                                               log2 |Fn |

Figure 1: Equation (2): Time complexity grows linearly with fooling set size, inversely with
introspection budget

   These information-theoretic bounds enable the separation proofs in Section 24. For the pointer-
chase language Lk , we will construct fooling sets with M = 2αm where m = Θ(n/k), yielding:
                                                      α · n/k                          n
                                                                                                
                              T (n) = Ω                                  =Ω                                                    (8)
                                                  (k − 1) · log2 n               k(k − 1) log2 n
In this overview bound, constants α, c are absorbed into Ω(·) for readability. by applying equation (2)
at depth k−1. The upper bound construction achieves O(n) time at depth k through sequential
table lookups, establishing the strict separation Lk ∈ Psi-Pk \ Psi-Pk−1 .


9     Target Language Lk (Pointer-Chase)
Assumptions & Regime. We work in the restricted regime: deterministic computation, single
pass over the input, no advice, and no randomness. The ι-interface is frozen by Table 1 with per-step
budget
                                B(d, n) = c · d · log2 n, c ≥ 1 fixed.
Every computation step performs exactly one ιj call with payload injected into the transition function
that step; see Definition 3.6. Transcript accounting follows from Lemma 8.2 (Budget Lemma) and
Table 1.

                                                                14
                                               Lower Bound
                                           T = Ω(log2 M/B(d, n))
                     distinguishability                               error probability
                             Fooling Bound                       Fano Bound
                                Eq. (2)                            Eq. (3)
                               Worst-case                        Average-case


                                             Budget Lemma
                                                   Eq. (1)
                                           ≤2 T ·B(d,n) transcripts



                                                   Input Space
                                                    |Fn | = M

Figure 2: Complete derivation flow: from input complexity through transcript bounds to time lower
bounds

   Mini-Recap

   One ιj -call per step; per-step bit budget B(d, n) = c · d · log2 n; deterministic; no advice; no
   randomness; transcript length ≤ T · B(d, n) bits (Table 1; Budget Lemma).


Setup and Encoding. Parameters: fix an integer k ≥ 2. For a universe size m, the input consists
of k functions T1 , . . . , Tk : [m] → [m], a tail predicate b : [m] → {0, 1}, and a designated start index
s ∈ [m] (see Remark 9.1). The canonical bit-encoding stores each Tj as an m-entry table with values
in [m] using ⌈log2 m⌉ bits per entry, and b as m bits. Thus the total input length is

                             n = k m ⌈log2 m⌉ + |{z}
                                                 m = Θ(k m log2 m).
                                   |       {z       }
                                          tables         tail

Equivalently, for fixed k, we will use m = Θ(n/k), and we keep constants explicit until the final Ω(·)
line.

Remark 9.1 (Start index size). Including the starting index s ∈ [m] into the input description
changes the total input length by at most O(1) bits and does not affect any asymptotic bounds used
below.

Definition 9.2 (Language Lk ). Let u0 := s and, for j ∈ {1, . . . , k}, define uj := Tj (uj−1 ). The
machine accepts the input iff b(uk ) = 1. We denote this language by Lk .

Remark 9.3 (Canonical lower-bound tools). We refer to the following canonical tools throughout:

   • Lemma 8.2 (Budget Lemma) and Table 1

   • Ψ–Fooling Bound (Theorem 8.4)

   • Ψ–Fano Bound (Lemma 8.5)

                                                        15
Remark 9.4 (Aliases for Ψ–Fooling and Ψ–Fano). Within this section, we refer to the canonical
statements in the lower-bound tools as Ψ–Fooling (Theorem 8.4) and Ψ–Fano (Lemma 8.5).
Lemma 9.5 (Single-Pass Access for Lk ). In the restricted regime (deterministic, one-pass, no-advice,
no-randomness) with ι-interface B(d, n) = c · d · log2 n, the encoding layout T1 ∥ T2 ∥ · · · ∥ Tk ∥ b
admits a single-pass evaluation strategy: in phase j, the index uj−1 is maintained using O(log m)
workspace; exactly one ιj -call is made per step, and no random access across blocks is required.
Theorem 9.6 (UB at depth k). Assume the restricted regime (deterministic, single pass, no advice,
no randomness) and Table 1. There exists a depth-k Ψ-algorithm deciding Lk in time O(n) and
workspace O(log m). The proof follows the phase-by-phase single-pass strategy of Lemma 9.5.
Proof. We execute a k-phase sequential scan of the input, conforming to the one-pass constraint. In
Phase j ∈ {1, . . . , k} we read the table of Tj left-to-right and maintain a single index register storing
uj−1 ∈ [m] and its update to uj = Tj (uj−1 ). During Phase j, each computation step uses exactly one
ιj call per step to inject the per-step payload into δ, enabling selectors-only access to any permitted
local view (Table 1); in particular, this enforces the per-step information bound B(d, n) = c
cdotd
cdot log2 n without exceeding it. No random access is needed: we compute uj by a single pass over
the Tj table, updating the index when the row for uj−1 is encountered.
    After completing Phase k, we scan the b array once and read b(uk ) at the designated position.
Accounting: each phase scans a disjoint Θ(m log m)-bit block once, so total I/O is O(n). The
workspace keeps only the current phase counter, the index uj and constant-many loop variables,
which is O(log m) bits. Preconditions are satisfied and the per-step ι usage complies with Table 1.
Lemma 9.7 (Fooling family for Lk ). There exists a family {Fn }n with |Fn | = 2αm for a constant
α > 0, such that any depth-(k−1) Ψ-algorithm in the restricted regime produces identical transcripts
on distinct x, x′ ∈ Fn while the answers differ via b(uk ).
Proof. Fix T1 , . . . , Tk−1 and fix any subset S ⊆ [m] of size |S| ≥ 0.9 m. Consider instances that
agree on all components except on (Tk ↾ S, b ↾ S); within S, vary Tk and b arbitrarily. Under the
restricted regime and budget B(k−1, n) = c (k−1) log2 n (Table 1), any depth-(k−1) machine that
runs for fewer than T steps can see at most T · B(k−1, n) bits across the entire computation by
Lemma 8.2 (Budget Lemma). For appropriate T = o(m), the final-layer degrees of freedom on S
dominate, so there exist distinct (Tk , b) and (Tk′ , b′ ) in this family that induce identical transcripts
yet route uk into positions with different b-labels. Hence |Fn | ≥ 2αm for some constant α ∈ (0, 1); in
particular we can take α ≈ 0.9 by construction. This is the standard last-layer entropy argument
adapted to the Ψ-budgeted setting.
Theorem 9.8 (LB at depth k−1). Assume the restricted regime and Table 1. Any depth-(k−1)
Ψ-algorithm deciding Lk requires
                                                           n
                                                                 
                                     T (n) = Ω                      .
                                                     k (k−1) log2 n
Proof. By Lemma 9.7, there is a fooling family of size |Fn | = 2αm with α > 0 and m = Θ(n/k).
Applying the Ψ–Fooling Bound (Theorem 8.4) at depth (k − 1) and using Lemma 8.2 (Budget
Lemma) and Table 1 yields
                        log |Fn |          αm                    n
                                                                                   
                   T ≥             =                  = Ω                  ,
                       B(k − 1, n)   c (k − 1) log2 n     k (k − 1) log2 n
keeping c and α explicit until the asymptotic form. In particular, T ≥ αm/(c(k − 1) log2 n). Here
constants α, c > 0 are absorbed into the Ω(·) notation.

                                                     16
Figure 3: Fooling set size analysis for Lk pointer-chase language. Plot shows log2 (M ) (distinguishable
instances, bits) vs. m (table size) with theoretical bound y = α · m where α ≈ 0.9. Linear
relationship confirms that |Fn | = 2αm fooling families can be constructed, validating the lower
bound T = Ω(n/(k(k−1) log2 n)) via the Ψ-Fooling framework. Data points: synthetic values from
theoretical formula; line: theoretical prediction.


Anti-Simulation Preview.

Remark 9.9 (Average-case via Ψ–Fano). For average-case instances of Lk , combining the same
budget accounting with Ψ–Fano (Lemma 8.5) yields the standard mutual-information bound; we do
not pursue the optimization here, as our focus is the worst-case separation.

    We establish the anti-simulation hook showing that depth (k−1) cannot polynomially simulate
depth k even with transcript access bounded by B(d, n), since the final-layer entropy revealed only
at depth k cannot be recovered within the (k−1) budget. The full statement and proof strategy are
given in Section 11.


10     Target Language Lphase
                        k     (Phase-Locked Access)
Assumptions & Regime. We work in the restricted regime: deterministic, one-pass, no advice, no
randomness. The ι-interface specification follows Table 1 with per-step budget B(d, n) = c · d · log2 n.
Budget accounting and transcript limitations are governed by Lemma 8.2 (Budget Lemma). All
computational steps perform exactly one ιj call per step as specified in Table 1. All logarithms are
base 2.



                                                  17
   Mini-Recap

   One ιj -call per step; per-step bit budget B(d, n) = c · d · log2 n; deterministic; no advice; no
   randomness; transcript length ≤ T · B(d, n) bits (Table 1; Budget Lemma).


Setup and Phase-Lock Constraint. Fix a query position q ∈ [m] as a global constant (not
counted toward input size). For j ∈ [k], the phase snapshot is a function Sj : [m] → {0, 1}ℓ with
ℓ = ⌈log2 m⌉. Phase-Lock Constraint (Formal): Each snapshot Sj is accessible exclusively
through interface ιj . This enforces information-theoretic separation: any algorithm with depth d < k
cannot distinguish instances differing only in Sd+1 , . . . , Sk , as the required interfaces ιd+1 , . . . , ιk
are unavailable within the computational model. The constraint is enforced by the budget B(d, n)
from Lemma 8.2, which limits total information exposure per computation. In particular, at every
step, the machine performs exactly one ιj call per step to obtain the bounded codeword used by the
transition function.

Definition 10.1 (Language Lkphase). Input: phase snapshots S1 , . . . , Sk : [m] → {0, 1}ℓ with
ℓ = ⌈log2 m⌉, and a query q ∈ [m]. Computation: extract vj := Sj (q) using ιj for each j ∈ [k].
Output: accept iff f (v1 , . . . , vk ) = 1 for a fixed Boolean function f : {0, 1}kℓ → {0, 1}. Encoding size:
n = k · m · ℓ bits.

Theorem 10.2 (UB at depth k). There exists a depth-k Ψ-algorithm deciding Lphase
                                                                           k     in time O(n)
and O(log m) workspace.

Proof. Run a k-phase scan. In phase j, stream through Sj using exactly one ιj call per step to access
the current snapshot view; when the stream position equals q, read vj = Sj (q) and store it. Across
all phases, we store only v1 , . . . , vk plus counters, totaling O(kℓ) = O(log m) bits. After phase k,
compute f (v1 , . . . , vk ) and accept accordingly. The total I/O is O(n) and workspace is O(log m).

Lemma 10.3 (Transcript Collision Lemma). There exists a family Fn with |Fn | = 2αmℓ for a fixed
constant α > 0, such that any depth-(k−1) Ψ-algorithm in the restricted regime produces identical
transcripts on distinct x, x′ ∈ Fn while f (v1 , . . . , vk ) differs between these instances.

Proof. Fix S1 , . . . , Sk−1 and the values v1 , . . . , vk−1 at position q. Vary only Sk (q) over all 2ℓ
possibilities, and define f so that roughly half of these instances accept and half reject. This yields
|Fn | ≥ 2ℓ = 2⌈log2 m⌉ . By Table 1, a depth-(k−1) algorithm has per-step budget B(k−1, n) =
c (k−1) log2 n and, by phase-lock, no access to Sk (access is accessible only via ιk ). Consequently,
its entire transcript across phases 1, . . . , k−1 is independent of Sk (q), so all such instances yield
identical transcripts while differing in acceptance due to the Sk (q) choice.
    Information-Theoretic Analysis:

   1. Budget Constraint: By Lemma 8.2 (Budget Lemma), depth-(k−1) algorithms have per-step
      budget B(k−1, n) = c (k−1) log2 n, with total information exposure bounded by T · B(k−1, n)
      bits over T steps.

   2. Interface Limitation: Access to Sk requires ιk calls, which are unavailable at depth k−1 by
      definition of the computational model.

   3. Projection Property: All accessible information through ι1 , . . . , ιk−1 depends only on
      S1 , . . . , Sk−1 , creating a natural projection πk−1 : Ik → Ik−1 where Id represents instances
      accessible at depth d.


                                                      18
Figure 4: Phase-lock mechanism demonstration: Transcript collision visualization showing how
depth-(k−1) algorithms produce identical transcripts on instances differing only in Sk (q). Left panel:
Phase access pattern (phases 1 through k−1 accessible, phase k blocked). Right panel: Resulting
transcript hashes showing collision despite different acceptance outcomes. The phase-lock constraint
forces information-theoretic blindness to the distinguishing layer.


  4. Transcript Invariance: For any x, x′ ∈ Fn differing only in Sk , we have πk−1 (x) = πk−1 (x′ ),
     hence identical transcripts while f (v1 , . . . , vk ) differs.



Theorem 10.4 (LB at depth k−1). Any depth-(k−1) Ψ-algorithm deciding Lphase
                                                                      k     in the restricted
regime requires
                                              n
                                                      
                              T (n) = Ω                  .
                                         k(k−1) log2 n

Proof. By Lemma 10.3: |Fn | = 2αmℓ with m = Θ(n/k) and ℓ = ⌈log2 m⌉ = Θ(log2 n).
                                        log2 |Fn |
   By Ψ-Fooling (Theorem 8.4): T ≥ B(k−1,n)        .
   From Table 1: B(k − 1, n) = c · (k − 1) · log2 n.
                                       αm log2 m
   Substituting: T ≥ c·(k−1)·log
                          αmℓ
                                 n = c·(k−1)·log n .
                                2              2                           
   With m = Θ(n/k) and log2 m = Θ(log2 n): T = Ω                 n
                                                            k(k−1) log2 n       .


Figure Interpretation. The visualization demonstrates the core mechanism of phase-locked
separation: algorithmic computation at depth k−1 produces identical transcripts (right panel)
despite accessing different problem instances. The left panel shows the access pattern where
ι1 , . . . , ιk−1 interfaces are available but ιk is blocked by the computational model. This interface-
based restriction creates an information bottleneck that prevents depth-(k−1) algorithms from
distinguishing instances that differ only in Sk (q), even when these instances have different acceptance
outcomes via f (v1 , . . . , vk ).




                                                   19
Research Significance. The phase-locked access mechanism introduces a novel separation tech-
nique in computational complexity theory. Unlike traditional diagonalization or oracle construction
methods, phase-locking leverages interface accessibility constraints to create information-
theoretic barriers. This approach has several implications:

   1. Methodological Innovation: Interface-based separation provides a new tool for proving
      computational hierarchy results, potentially applicable to other computational models.
   2. Practical Relevance: Phase-locked systems naturally arise in distributed computing and
      secure multi-party computation, where different parties have access to different data phases.
   3. Theoretical Foundation: The technique bridges information theory and computational
      complexity, offering a framework for analyzing problems where computational access itself is
      constrained.

   This work establishes phase-locked access as a fundamental primitive for hierarchy separation,
with potential applications beyond the Psi-TM model.

Separation Strength. The phase-lock mechanism yields a strong separation: without ιk , algo-
rithms are information-theoretically blind to the final distinguishing layer, forcing identical transcripts
that nevertheless differ in acceptance only when the missing phase is revealed. This conclusion relies
on the constrained ι-interface (Table 1) and the budget B(d, n) from Lemma 8.2.


11     Anti-Simulation Hook
Motivation & Context. Previous sections establish a depth hierarchy via the Budget/Fooling
framework (see the Budget Lemma 8.2 and the Ψ-Fooling bound 8.4). One may ask whether a
depth-(k−1) algorithm could simulate a single ιk call using many ιk−1 calls, thereby bypassing our
separation. We provide a quantitative no-poly-simulation result that eliminates this possibility.

Model Preconditions. Throughout this section we work under the restricted computational
model used elsewhere in this paper: deterministic, one-pass, no-advice, no-randomness; exactly one
ιj call per step with information budget B(d, n) = c · d · log2 n; payloads are injected only through
the transition function δ; workspace is O(log m) and total I/O is O(n). These assumptions are
required to apply the Budget Lemma 8.2 and the associated Ψ-Fooling arguments 8.4.

Simulation Attack Model. Consider a depth-(k−1) algorithm attempting to simulate a single
ιk call using s calls to ιk−1 , where s = poly(n). We analyze when this violates fundamental budget
constraints.
Definition 11.1 (Simulation Attempt). A depth-(k−1) Ψ-algorithm A attempts to simulate
ιk (payload) by using s sequential calls ιk−1 (payload1 ), . . . , ιk−1 (payloads ) where s = nβ for a
constant β > 0.
Theorem 11.2 (No-Poly-Simulation). Fix k ≥ 2 and n ≥ 2. Let a depth-(k−1) Ψ-algorithm attempt
to simulate one ιk call using s = nβ calls to ιk−1 in the restricted model. A budget violation (hence
impossibility of simulation) occurs whenever
                                                                  
                                                  log2        k
                                                             k−1
                                            β ≥                        .
                                                    log2 n

                                                    20
Equivalently,
            the simulation condition s · B(k−1, n) ≥ B(k, n) holds if and only if β · log2 n ≥
log2 k−1 .
      k


Proof. By Definition 11.1, the simulation uses s = nβ calls to ιk−1 , each limited by B(k−1, n) =
c · (k−1) · log2 n bits. The total budget consumed by the attempt is therefore

                                s · B(k−1, n) = nβ · c · (k−1) · log2 n.

For a meaningful emulation of a single ιk access, one must at least match its information budget
from Table 1 and the Budget Lemma 8.2, i.e.,

                              s · B(k−1, n) ≥ B(k, n) = c · k · log2 n,

which simplifies to
                                                      k
                                             nβ ≥        .
                                                     k−1
                                     
Equivalently, β · log2 n ≥ log2 k−1
                                 k
                                    . This is exactly the claimed threshold. Under the restricted
model the allocated per-step budget at depth (k−1) is only B(k−1, n) = c · (k−1) · log2 n by the
Budget Lemma 8.2. Therefore
                      s B(k−1, n)        k−1                         log2 (k/(k−1))
                                  = nβ ·     ≥ 1        ⇐⇒     β ≥                  .
                        B(k, n)           k                               log2 n
Hence the simulation attempt triggers a budget violation exactly at this inequality, contradicting
the model assumptions.

Remark 11.3 (Asymptotic form). For fixed k and any constant β > 0, the threshold
                                                                                  large n the inequality
log2 (k/(k−1))/ log2 n = Θ(1/ log2 n) tends to 0 as n grows; thus for sufficiently
                                                                  log2 (k/(k−1))
in Theorem 11.2 holds. Equivalently, the threshold is β = Ω            log2 n     with explicit constant
log2 (k/(k−1)).

Lemma 11.4 (Failure Mode Analysis). The No-Poly-Simulation barrier could be bypassed only if
one of the following occurs:

  1. Super-logarithmic budget: B(d, n) = ω(log2 n) allowing polynomial total budget.

  2. Randomized simulation: Access to random bits enabling probabilistic payload compression.

  3. Advice mechanism: Non-uniform advice encoding ιk information.

  4. Multi-pass access: Multiple sequential scans of input enabling state accumulation.

Each violates our restricted computational model assumptions (deterministic, one-pass, no-advice,
no-randomness; exactly one ιj call per step; B(d, n) = c d log2 n; O(log m) workspace; payload
injection only via δ).

Proof. Mode 1: If B(d, n) = nγ for some γ > 0, then the total available budget becomes polynomial,
allowing simulation. Mode 2: Random bits could enable compression of the ιk payload into multiple
ιk−1 calls, invalidating the determinism constraint. Mode 3: An advice string could precompute
ιk responses, eliminating the need for simulation. Mode 4: Multiple passes could accumulate state
across scans, simulating deeper access in violation of the one-pass constraint. Our model explicitly
excludes all four modes; hence none applies.

                                                   21
Figure 5: Budget violation ratio s B(k−1,n)
                                   B(k,n)   as a function of β for several k. The vertical line marks
the exact threshold β = log2 (k/(k−1))/ log2 n.


Corollary 11.5 (Quantitative Separation Barrier). In the restricted regime, depth-(k−1) algorithms
face an exponential barrier: simulating depth-k capability requires 2Ω(log2 n) = nΩ(1) budget, while only
O(log2 n) is allocated at depth (k−1). Keeping constants c, α, β explicit until asymptotic notation,
the quantitative gap is governed by the exact inequality

                                                                       log2 (k/(k−1))
                 nβ · c · (k−1) · log2 n ≥ c · k · log2 n   ⇐⇒   β ≥                  .
                                                                            log2 n

Integration with LB Proofs. This anti-simulation hook reinforces the lower bounds from prior
sections by removing the main potential workaround for depth-(k−1) algorithms. The quantitative
gap ensures our hierarchy is robust against polynomial-time simulation attacks. In particular, the
dependency on LB arguments via the Budget Lemma 8.2 and the Ψ-Fooling bound 8.4 persists
unchanged: any attempt to trade many ιk−1 calls for a single ιk call triggers a budget violation.

Research Significance. The No-Poly-Simulation result establishes computational barriers beyond
information-theoretic separation. Even with arbitrarily complex payload designs (still injected
only via δ), fundamental budget constraints prevent simulation under our deterministic, one-pass,
no-advice model with logarithmic information budget.


12     Related Work
This work studies minimal introspection requirements across the four classical complexity barriers:
relativization, natural proofs, proof complexity, and algebraization[5, 85, 27, 1]. Proven results
are oracle-relative; other statements are partial/conditional. We indicate plausible targets where
justified and mark unrelativized sufficiency as open.



                                                     22
13     Formal Definitions
13.1    Complexity Barriers
Definition 13.1 (Relativization Barrier). A complexity class separation C1 ̸= C2 relativizes if for
every oracle A, C1A ̸= C2A [5].
Definition 13.2 (Natural Proofs Barrier). A proof technique is natural if it satisfies[85]:
  1. Constructivity: The proof provides an efficient algorithm to distinguish random functions
     from functions in the target class
  2. Largeness: The proof technique applies to a large fraction of functions
  3. Usefulness: The proof technique can be used to prove lower bounds
Definition 13.3 (Proof Complexity Barrier). A proof system has polynomial-size proofs for a
language L if there exists a polynomial p such that for every x ∈ L, there exists a proof π of size at
most p(|x|) that can be verified in polynomial time[27].
Definition 13.4 (Algebraization Barrier). A complexity class separation algebrizes if it holds
relative to any low-degree extension of the oracle[1].

13.2    Psi-TM barrier status
Definition 13.5 (Barrier status (conservative)). Psi-TM with introspection depth k is said to make
progress against a barrier if there is an oracle-relative separation or a partial/conditional statement
consistent with selectors-only semantics and the information budget (Lemma 8.2).


14     Relativization Barrier: k >= 1
Theorem 14.1 (Relativization Barrier Minimality). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. The relativization barrier requires
introspection depth d ≥ 1 to bypass.
Proof. We prove both the necessity and sufficiency of k ≥ 1.
    Necessity (d = 0 is insufficient): Let M be a Psi-TM with introspection depth d = 0. Then
M has no introspection capabilities and behaves identically to a standard Turing machine. By the
relativization barrier, M cannot solve problems that relativize.
    Sufficiency (d ≥ 1 is sufficient): We construct a Psi-TM with introspection depth d = 1 that
can bypass the relativization barrier.
    Construction: Consider the language Lrel = {w ∈ {0, 1}∗ | structural depth d(w) = 1}.
    Standard TM Limitation: For any oracle A, standard Turing machines are not known to
solve Lrel in polynomial time; conservatively (oracle-relative), such problems remain hard when the
separation relativizes.
    Psi-TM Solution: A Psi-TM with introspection depth d = 1 uses one call y = ι1 (C, n) and
selectors over decode1 (y) to extract the needed bounded-depth summary, respecting the per-step
budget B(1, n) (Lemma 8.2).
    Budget accounting: Each call to ι1 has at most 2B(1,n) outcomes; over t = O(n) steps there
are at most 2t·B(1,n) outcome sequences (Lemma 8.2).
    This establishes that introspection depth k = 1 is both necessary and sufficient to bypass the
relativization barrier.

                                                  23
15     Natural Proofs Barrier: k >= 2
Theorem 15.1 (Natural Proofs Barrier Minimality). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. The natural proofs barrier requires
introspection depth d ≥ 2 to bypass.
Proof. We prove both the necessity and sufficiency of k ≥ 2.
    Necessity (d ≤ 1 is insufficient): Let M be a Psi-TM with introspection depth d ≤ 1. The
introspection function ιd can only access depth-≤ 1 structural patterns, which are insufficient to
distinguish between random functions and functions with specific structural properties that natural
proofs target.
    Sufficiency (d ≥ 2 is sufficient): We construct a Psi-TM with introspection depth d = 2 that
can bypass the natural proofs barrier.
    Construction: Consider the language Lnat defined as follows:

                    Lnat = {w ∈ {0, 1}∗ |w has depth-2 structural patterns
                                         that satisfy natural proof properties}                  (9)

    Standard TM Limitation: Standard Turing machines are believed not to solve Lnat efficiently;
this is a conservative/heuristic statement grounded in the natural proofs barrier.
    Psi-TM Solution: A Psi-TM with introspection depth d = 2 performs calls to ι2 (C, n) and uses
selectors over decode2 (y) to obtain depth-2 summaries; per call outcomes are bounded by 2B(2,n)
(Lemma 8.2).
    Budget accounting: Each call to ι2 has at most 2B(2,n) outcomes; over t = poly(n) steps there
are at most 2t·B(2,n) outcome sequences (Lemma 8.2).
    This establishes that introspection depth k = 2 is both necessary and sufficient to bypass the
natural proofs barrier.


16     Proof Complexity Barrier: k >= 2
Theorem 16.1 (Proof Complexity Barrier Minimality). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. The proof complexity barrier requires
introspection depth d ≥ 2 to bypass.
Proof. We prove both the necessity and sufficiency of k ≥ 2.
    Necessity (d ≤ 1 is insufficient): Let M be a Psi-TM with introspection depth d ≤ 1. The
introspection function ιd can only access depth-≤ 1 structural patterns, which are insufficient to
analyze complex proof structures that require depth-2 analysis.
    Sufficiency (d ≥ 2 is sufficient): We construct a Psi-TM with introspection depth d = 2 that
can bypass the proof complexity barrier.
    Construction: Consider the language Lproof where

                          Lproof = {w ∈ {0, 1}∗ |w encodes a valid proof
                                                 with depth-2 structure}                       (10)

    Standard TM Limitation: Standard Turing machines are believed not to efficiently verify
proofs in Lproof ; this reflects conservative expectations from proof complexity barriers.
    Psi-TM Solution: A Psi-TM with introspection depth d = 2 uses selectors over decode2 (ι2 (C, n))
to extract bounded-depth summaries for verification, with per-step outcomes bounded by 2B(2,n)
(Lemma 8.2).

                                                24
    Budget accounting: Each call to ι2 has at most 2B(2,n) outcomes; over t = poly(n) steps there
are at most 2t·B(2,n) outcome sequences (Lemma 8.2).
    This establishes that introspection depth k = 2 is both necessary and sufficient to bypass the
proof complexity barrier.


17    Algebraization Barrier: k >= 3
Theorem 17.1 (Algebraization Barrier Minimality). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. The algebraization barrier requires
introspection depth d ≥ 3 to bypass.
Proof. We prove both the necessity and sufficiency of k ≥ 3.
    Necessity (d ≤ 2 is insufficient): Let M be a Psi-TM with introspection depth d ≤ 2. The
introspection function ιd can only access depth-≤ 2 structural patterns, which are insufficient to
analyze algebraic structures that require depth-3 analysis.
    Sufficiency (d ≥ 3 is sufficient): We construct a Psi-TM with introspection depth d = 3 that
can bypass the algebraization barrier.
    Construction: Consider the language Lalg where

                      Lalg = {w ∈ {0, 1}∗ |w encodes an algebraic structure
                                           with depth-3 properties}                             (11)

    Standard TM Limitation: Standard Turing machines are believed not to efficiently solve Lalg ;
this is a conservative statement aligned with algebraization barriers.
    Psi-TM Solution: A Psi-TM with introspection depth d = 3 uses selectors over
decode3 (ι3 (C, n)); per-step outcomes are bounded by 2B(3,n) (Lemma 8.2).
    Budget accounting: Each call to ι3 has at most 2B(3,n) outcomes; over t = poly(n) steps there
are at most 2t·B(3,n) outcome sequences (Lemma 8.2).
    This establishes that introspection depth k = 3 is both necessary and sufficient to bypass the
algebraization barrier.


18    Barrier Hierarchy
Theorem 18.1 (Barrier Hierarchy). The complexity barriers form a strict hierarchy based on
introspection depth requirements:
  1. Relativization: requires k ≥ 1

  2. Natural Proofs: requires k ≥ 2

  3. Proof Complexity: requires k ≥ 2

  4. Algebraization: requires k ≥ 3
Proof. This follows directly from the individual barrier minimality theorems above. The hierarchy is
strict because:

  1. A Psi-TM with k = 1 can bypass relativization but not natural proofs or proof complexity

  2. A Psi-TM with k = 2 can bypass relativization, natural proofs, and proof complexity but not
     algebraization

                                                25
   3. A Psi-TM with k = 3 can bypass all four barriers

     This establishes the strict hierarchy of barrier bypass requirements.


19      Optimal Introspection Depth
Theorem 19.1 (Optimal Introspection Depth). The optimal introspection depth for bypassing all
four complexity barriers is k = 3.

Proof. Sufficiency: By the barrier hierarchy theorem, k = 3 is sufficient to bypass all four barriers.
   Minimality: We prove that k = 2 is insufficient by showing that algebraization cannot be
bypassed with depth-2 introspection.
   Adversary Construction: For any Psi-TM M with introspection depth k = 2, we construct
an adversary that defeats M on algebraization problems:

   1. The adversary generates inputs with depth-3 algebraic structures

   2. For any call y = ι2 (C, n), the adversary ensures selectors over decode2 (y) reveal only depth-2
      projections

   3. The machine cannot distinguish between valid and invalid algebraic structures

   4. Therefore, M must err on some inputs

     This establishes that k = 3 is both necessary and sufficient for optimal barrier bypass.


20      Complexity Class Implications
Theorem 20.1 (Complexity Class Separations). For each barrier bypass level k, there exist complexity
class separations that can be proven:

  1. k = 1: Psi-P1 ̸= Psi-PSPACE1 (relativizing)

  2. k = 2: Psi-P2 ̸= Psi-NP2 (natural proofs)

  3. k = 3: Psi-P3 ̸= Psi-PSPACE3 (algebraizing)

Proof. k = 1 Separation: Use the relativization-bypassing language Lrel to separate Psi-P1 from
Psi-PSPACE1 .
    k = 2 Separation: Use the natural-proofs-bypassing language Lnat to separate Psi-P2 from
Psi-NP2 .
    k = 3 Separation: Use the algebraization-bypassing language Lalg to separate Psi-P3 from
Psi-PSPACE3 .
    Each separation follows from the corresponding barrier bypass capability and the impossibility
of standard Turing machines solving these problems.




                                                  26
21    Outlook — Barriers
This work establishes the minimal introspection requirements for bypassing classical complexity
barriers:

  1. Relativization: requires k ≥ 1

  2. Natural Proofs: requires k ≥ 2

  3. Proof Complexity: requires k ≥ 2

  4. Algebraization: requires k ≥ 3

    The optimal introspection depth for bypassing all barriers is k = 3, providing a complete
characterization of the relationship between introspection depth and barrier bypass capability in the
Psi-TM model.
    These results provide a rigorous foundation for understanding the minimal computational
requirements for overcoming classical complexity barriers.


22    Related Work
The Psi-TM model extends standard Turing machines with minimal introspection capabilities, where
introspection depth is limited to a constant d = O(1). Previous work established that Psi-TM can
bypass all four classical complexity barriers with minimal introspection requirements: relativization
requires d ≥ 1, natural proofs and proof complexity require d ≥ 2, and algebraization requires d ≥ 3.
    The fundamental question addressed in this work is whether there exists a strict hierarchy of
computational power based on introspection depth:
    Main Question: Does Psi-TMd ⊊ Psi-TMd+1 hold for all d ≥ 1?
    This question has important implications for understanding the relationship between introspection
depth and computational capability. A positive answer would establish that each additional level of
introspection provides strictly more computational power, while a negative answer would indicate a
collapse point beyond which increased introspection offers no additional advantage.
    Our Contributions:

  1. Strict Hierarchy Theorem: For each k ≥ 1, we prove Psi-TMk ⊊ Psi-TMk+1

  2. Explicit Language Construction: We construct languages Lk that separate each level

  3. Structural Depth Analysis: We characterize the structural patterns that require depth
     k + 1 introspection

  4. Collapse Threshold Investigation: We analyze whether the hierarchy collapses at some
     finite k ∗

  5. Complexity Class Implications: We establish corresponding separations in complexity
     classes




                                                 27
23       Lower-Bound Toolkit
23.1     Introspection Depth Hierarchy
Definition 23.1 (Psi-TM d Model). For each d ≥ 1, a Psi-TM with introspection depth d is a
7-tuple:
                               MΨd = (Q, Σ, Γ, δ, q0 , F, ιd )
where:

  • (Q, Σ, Γ, δ, q0 , F ) is a deterministic Turing machine

  • ιd : Config × N → {0, 1}≤B(d,n) is the d-limited introspection operator

  • Ψk denotes the range of the canonical code Ck over admissible atoms of depth ≤ k

  • d is a constant independent of input size

Definition 23.2 (Structural Depth). For a string w ∈ Γ∗ , the structural depth d(w) is defined
recursively:

  • d(w) = 0 if w contains no nested patterns

  • d(w) = 1 + max{d(w1 ), d(w2 )} if w = w1 ◦ w2 where ◦ represents a structural composition

  • d(w) = k if w contains k-level nested structural patterns

Selectors (single semantics). Introspective access is restricted to selectors over y = ιd (C, n):
VIEW_STATE(y), VIEW_HEAD(y), and VIEW_WIN(y, j) for j ≤ d. Legacy INT_* names are
aliases to these views.

23.2     Complexity Classes
Definition 23.3 (Psi-P d Class). The class Psi-Pd consists of languages recognizable by Psi-TM
with introspection depth d in polynomial time.

Definition 23.4 (Psi-NP d Class). The class Psi-NPd consists of languages with polynomial-time
verifiable certificates using Psi-TM with introspection depth d.

Definition 23.5 (Psi-PSPACE d Class). The class Psi-PSPACEd consists of languages recognizable
by Psi-TM with introspection depth d using polynomial space.


24       Explicit Language Constructions
24.1     Tree Evaluation Language
Definition 24.1 (Binary Tree Encoding). A binary tree T is encoded as a string encode(T ) ∈ {0, 1}∗
as follows:

  • Each node is encoded as a triple (v, l, r) where v is the node value, l is the left subtree encoding,
    and r is the right subtree encoding

  • Leaf nodes are encoded as (v, ε, ε)


                                                  28
  • The encoding uses a prefix-free code to separate node components

Definition 24.2 (Tree Evaluation Language Lk ). For each k ≥ 1, define Lk as the set of strings
encode(T )#1n where:

  • T is a binary tree of depth exactly k + 1

  • Leaves are labeled with bits

  • Root evaluates to 1 under Boolean logic (AND/OR gates at internal nodes)

Claim 1. For each k ≥ 1, Lk ∈ Psi-Pk+1 .

Proof. We construct a Psi-TM M with introspection depth k + 1 that recognizes L k in polynomial
time.
   Algorithm:

  1. Parse the input to extract encode(T ) and 1n

  2. Obtain y = ιk+1 (C, n) and use selectors over decodek+1 (y) to access the tree structure up to
     depth k+1

  3. Verify that the tree has depth exactly k + 1

  4. Evaluate the tree bottom-up using the structural information

  5. Accept if and only if the root evaluates to 1

     Time Analysis:

  1. Parsing: O(n)

  2. Depth verification: O(n) using selectors over decodek+1 (y)

  3. Tree evaluation: O(n) since we have complete structural information

  4. Total time: O(n)

     Therefore, Lk ∈ Psi-Pk+1 .


25      Main Result: Strict Hierarchy
25.1     Theorem A: Strict Inclusion
Theorem 25.1 (Strict Hierarchy). Assumes the restricted regime (deterministic, single pass, no
advice, no randomness) and uses Table 1. For all k ≥ 1:

                                      Psi-TMk ⊊ Psi-TMk+1

Equivalently:
                                        Psi-Pk ⊊ Psi-Pk+1




                                                29
Proof. We prove this by showing that for each k ≥ 1, the language Lk satisfies:

                                                      / Psi-Pk
                                 Lk ∈ Psi-Pk+1 but Lk ∈

    Membership in Psi-P k+1: This follows from the claim above.
    Non-membership in Psi-P k: We prove that no Psi-TM with introspection depth k can
recognize L k in polynomial time.
Lemma 25.2 (Depth-k Limitation). Assumes the restricted regime (deterministic, single pass, no
advice, no randomness) and uses Table 1. Any Psi-TM with introspection depth k cannot distinguish
between trees of depth k + 1 and trees of depth k in polynomial time.

Proof. Key Insight: Introspection depth k provides access only to patterns of depth ≤ k, but
cannot access depth k + 1 patterns.
   Detailed Proof: For trees T1 (depth k + 1) and T2 (depth k):

  1. Tree Structure Analysis:

       • Both trees have identical node structure up to level k
       • T1 has additional level k + 1 with leaf values
       • T2 terminates at level k with leaf values

  2. Selector Analysis: Decoding y = ιk (C, n) exposes only depth-≤ k tags and values; level k+1
     information is not accessible to selectors.

  3. Selector Equality: Since depth-≤ k features coincide, all selectors over decodek (ιk (C, n))
     return identical values on encode(T1 ) and encode(T2 )

  4. Depth-k agreement: Both inputs share the same depth-k features; therefore selectors agree
     at depth k.

  5. Selector Equality: Since depth-≤ k features coincide, all selectors over decodek (ιk (C, n))
     return identical values on encode(T1 ) and encode(T2 )

  6. Machine Limitation: Machine M with introspection depth k receives identical introspection
     responses for both inputs and therefore cannot distinguish between them.

   Adversary Construction: For any Psi-TM M with introspection depth k, we construct an
adversary A that defeats M :
   Adversary Strategy:

  1. On input w = encode(T )#1n : ensure that for any call y = ιk (C, n), selectors over decodek (y)
     reveal only depth-≤ k features (for depth k+1 inputs, the depth-k projection is revealed).

  2. The adversary ensures that all selectors over decodek (ιk (C, n)) agree on w1 and w2 when one
     has depth k and the other k+1

   Information-Theoretic Argument:

  1. Let T1 be a tree of depth k + 1 and T2 be a tree of depth k

  2. Both trees have identical depth-k structural patterns


                                                30
  3. The introspection function ιk can only access depth-k information

  4. Therefore, all selectors over decodek (ιk (C, n)) agree on encode(T1 ) and encode(T2 )

  5. Machine M cannot distinguish between these inputs

  6. Since one input is in Lk and the other is not, M must err on at least one input



   Separation Proof: By Lemma 25.2, any Psi-TM with introspection depth k must either:

                          / Lk (false positive), or
  1. Accept some input w2 ∈

  2. Reject some input w1 ∈ Lk (false negative)

                            / Psi-Pk .
   This establishes that Lk ∈
                                                    / Psi-Pk , we have:
   Hierarchy Conclusion: Since Lk ∈ Psi-Pk+1 but Lk ∈

                                         Psi-Pk ⊊ Psi-Pk+1

   This holds for all k ≥ 1, establishing the strict hierarchy.

25.2      Theorem B: Lower Bound on Structural Depth
Theorem 25.3 (Structural Depth Lower Bound). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. For any language L ∈ Psi-Pk+1 \ Psi-Pk ,
there exists a family of inputs {wn }n≥1 such that:

  1. wn has length n

  2. wn requires structural depth k + 1 for recognition

  3. Any Psi-TM with introspection depth k requires Ω(nk+1 ) time to recognize wn

Proof. We construct explicit families of inputs that demonstrate the lower bound.
   Input Family Construction: For each n ≥ 1, construct wn as follows:

  1. Start with base pattern P0 = 01

  2. For each level i from 1 to k + 1:

          • Create pattern Pi = Pi−1 ◦ Pi−1 where ◦ represents structural composition
          • Pi has structural depth i

  3. wn = Pk+1 repeated to achieve length n

   Structural Depth Analysis:

  1. P0 has depth 0 (no nested patterns)

  2. P1 = P0 ◦ P0 has depth 1

  3. P2 = P1 ◦ P1 has depth 2
      .
  4. ..

                                                  31
  5. Pk+1 has depth k + 1

     Lower Bound Proof: Any Psi-TM with introspection depth k must:

  1. Pattern Analysis: Process wn by examining depth-k patterns only

  2. Information Limitation: Cannot access the depth k + 1 structural information

  3. Exhaustive Search Requirement: Must check all possible depth-k decompositions

     Complexity Analysis: For trees with n nodes and depth k + 1:

  1. Leaf Count at Level k+1: 2k leaves at level k + 1
                                                                               k
  2. Possible Configurations: Each leaf can be 0 or 1, giving 22 possible configurations

  3. Tree Size Relationship: For trees with n nodes, 2k = Θ(n1/(k+1) )
                                                         1/(k+1) )
  4. Required Checks: Machine must check 2Θ(n                        possible configurations

  5. Time Complexity: Each check requires Ω(n) time for pattern matching
                             1/(k+1) )
  6. Total Time: Ω(n · 2Θ(n              ) = Ω(nk+1 )

     Formal Justification:

                  Number of leaves at level k + 1 = 2k
                                                           k
                          Possible configurations = 22
                      For trees with n nodes: 2k = Θ(n1/(k+1) )
                                                               1/(k+1) )
                                 Required checks = 2Θ(n
                                  Time per check = Ω(n)
                                                                       1/(k+1) )
                                           Total time = Ω(n · 2Θ(n                 ) = Ω(nk+1 )

    Upper Bound: A Psi-TM with introspection depth k + 1 can recognize wn in O(n) time by
directly accessing the depth k + 1 pattern.
    This establishes the Ω(nk+1 ) lower bound for depth-k machines.


26     Adversary Arguments
26.1    Formal Adversary Construction
Theorem 26.1 (Adversary Lower Bound). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. For any Psi-TM M with introspection depth k,
there exists an adversary A such that: M cannot solve Lk against A.

Proof. We construct an explicit adversary strategy that defeats any depth-k Psi-TM.
   Adversary Strategy:

  1. Input Generation: For each n ≥ 1, the adversary generates two inputs:

        • w1 = encode(T1 )#1n where T1 has depth k + 1 and evaluates to 1

                                                    32
        • w2 = encode(T2 )#1n where T2 has depth k and evaluates to 0

  2. Introspection Response: When M calls INT_PATTERN(k) on input w:

        • If w has depth k: Return actual depth-k patterns
        • If w has depth k + 1: Return only the depth-k projection

  3. Consistency Maintenance: The adversary ensures that: All selectors over decodek (ιk (C, n))
     agree on w1 and w2

     Information-Theoretic Analysis:

  1. The introspection function ιk can only access depth-k information

  2. Both inputs w1 and w2 have identical depth-k structural patterns

  3. Machine M receives identical introspection responses for both inputs

  4. Therefore, M must produce the same output for both inputs

                          / Lk , M must err on at least one input
  5. Since w1 ∈ Lk and w2 ∈

    Error Probability: The adversary can generate inputs such that M errs with probability at
least 1/2 by ensuring that the machine cannot distinguish between valid and invalid inputs based
solely on depth-k information.
    This establishes that no depth-k Psi-TM can solve Lk against this adversary.


27     Complexity Class Implications
27.1    Class Separations
Theorem 27.1 (Complexity Class Separations). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. For all k ≥ 1:

                                 Psi-Pk ⊊ Psi-Pk+1 ⊊ PSPACE

                              Psi-NPk ⊊ Psi-NPk+1 ⊊ NPSPACE
                        Psi-PSPACEk ⊊ Psi-PSPACEk+1 ⊊ EXPSPACE

Proof. Strict Inclusions: Follow from the main hierarchy theorem and the explicit language
constructions.
    PSPACE Inclusions: Any Psi-TM with constant introspection depth can be simulated by
a standard Turing machine with polynomial space overhead, as shown in the formal definition
document.
    Proper Inclusions: The languages Lk demonstrate that the inclusions are proper, as they
belong to higher levels but not to lower levels of the hierarchy.




                                               33
27.2      Collapse Threshold Analysis
Theorem 27.2 (No Finite Collapse). Assumes the restricted regime (deterministic, single pass, no
advice, no randomness) and uses Table 1. The Psi-TM hierarchy does not collapse at any finite level
k∗ .

Proof. For any finite k ∗ , we can construct a language Lk∗ +1 that requires depth k ∗ + 1 introspection
but cannot be recognized by any depth-k ∗ Psi-TM.
   This follows from the explicit construction of Lk for each k ≥ 1 and the adversary arguments
that show the impossibility of depth-k machines recognizing depth-(k + 1) languages.


28      Algorithmic Results
28.1      Efficient Simulation
Theorem 28.1 (Efficient Psi-TM Simulation). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. Any Psi-TM Mpsi with d-limited introspection can
be simulated by a standard Turing machine M with slowdown O(n3 · f (d)), where f is a polynomial
function.

Proof. We present an algorithm for simulating Mpsi :

  Algorithm: Psi-TM Simulation

       1. Initialize state (q0 , ε, ε, ∅)

       2. while not in accepting or rejecting state do

           (a) Read current symbol a
           (b) Compute the required selectors from y = ιd (C, n)
           (c) Apply transition δ(q, a, ψ) = (q ′ , b, d)
           (d) Update configuration
           (e) Move head according to d

   Each introspection call takes O(n3 ) time by the structural depth computation algorithm. Total
simulation time: O(T (n) · n3 · f (d)).

28.2      Universal Psi-TM
Theorem 28.2 (Existence of Universal Psi-TM). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. There exists a universal Psi-TM Upsi
with d-limited introspection that can simulate any Psi-TM Mpsi with d-limited introspection with
polynomial slowdown.

Proof. We construct Upsi as follows:

  1. Encoding: Upsi takes as input a description of Mpsi and input string x

  2. Simulation: Upsi maintains the configuration of Mpsi on its tape

  3. Introspection: For each introspection call of Mpsi , Upsi computes the same introspection

                                                      34
  4. Transitions: Upsi applies the transition function of Mpsi based on the encoded description

   Since both machines have d-limited introspection, the simulation preserves the introspection
constraints. The slowdown is polynomial due to the overhead of interpreting the encoded machine
description and computing introspection calls.


29    Outlook — Hierarchy
We have established a strict hierarchy of Psi-TM models based on introspection depth, with the
following key results:

  1. Strict Hierarchy: For each k ≥ 1, Psi-TMk ⊊ Psi-TMk+1

  2. Explicit Constructions: We provided concrete language constructions Lk that separate each
     level

  3. Adversary Arguments: We constructed formal adversaries that demonstrate the impossibility
     of depth-k machines recognizing depth-(k + 1) languages

  4. Complexity Implications: We established corresponding separations in complexity classes

  5. No Collapse: We proved that the hierarchy does not collapse at any finite level

    These results provide a rigorous foundation for understanding the relationship between introspec-
tion depth and computational power in the Psi-TM model, opening new directions in computational
complexity theory and formal automata theory.


30    Outlook — STOC/FOCS Synthesis
The Psi-TM (Psi-Turing Machine) model extends standard Turing machines with minimal intro-
spection capabilities, where introspection depth is limited to a constant d = O(1). In conservative
terms, oracle-relative separations are proved, and other barrier statements are partial/conditional.
The fundamental question addressed in this work is whether there exists a strict hierarchy of
computational power based on introspection depth.
   Main Question: Does Psi-TMd ⊊ Psi-TMd+1 hold for all d ≥ 1?
   Our Contributions (oracle-relative):

  1. Strict Hierarchy (oracle-relative): For each k ≥ 1, we prove Psi-TMk ⊊ Psi-TMk+1
     relative to a suitable oracle

  2. Explicit Language Construction: We construct concrete languages Lk that separate each
     level

  3. Formal Adversary Arguments: We provide rigorous information-theoretic lower bounds

  4. Complexity Class Separations: We establish corresponding separations in complexity
     classes

  5. k = 3 as plausible target: Subject to algebraization lower bounds, k = 3 is a plausible
     simultaneous target; unrelativized sufficiency remains open


                                                 35
31       Preliminaries
31.1     Structural Depth
Definition 31.1 (Formal Structural Depth). For a string w ∈ {0, 1}∗ , the structural depth d(w) is
defined as:
                                    d(w) = min depth(Tw )
                                                 Tw
where the minimum is taken over all possible parsing trees Tw for w.
   Base cases:
   • d(ε) = 0 (empty string)
   • d(0) = d(1) = 0 (single symbols)
   Recursive case: For |w| > 1, d(w) = minw=uv {1 + max(d(u), d(v))} where the minimum is
taken over all binary partitions of w.
Lemma 31.2 (Well-Definedness of Structural Depth). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. The structural depth function d : {0, 1}∗ → N
is well-defined and computable in O(n3 ) time.
Proof. Well-Definedness:
   1. For strings of length ≤ 1, d(w) is explicitly defined
   2. For longer strings, the minimum exists because:
         • The set of possible partitions is finite (at most n − 1 partitions for length n)
         • Each partition yields a finite depth value
         • The minimum of a finite set of natural numbers exists
     Computability: We provide a dynamic programming algorithm:
     Correctness:
   1. Base cases are handled correctly
   2. For each substring w[i : j], we try all possible binary partitions
   3. The algorithm computes the minimum depth over all parsing trees
   4. Time complexity: O(n3 ) due to three nested loops



31.2     Psi-TM Model
Definition 31.3 (Psi-TM d Model). For each d ≥ 1, a Psi-TM with introspection depth d is a
7-tuple:
                               MΨd = (Q, Σ, Γ, δ, q0 , F, ιd )
where:
   • (Q, Σ, Γ, δ, q0 , F ) is a deterministic Turing machine
   • ιd : Γ∗ × Γ∗ × N → Ψd is d-limited introspection
   • Ψk denotes structural metadata of depth exactly k
   • k is a constant independent of input size

                                                   36
  Algorithm: Structural Depth Computation

       1. Input: String w = w1 w2 . . . wn

       2. Output: Structural depth d(w)

       3. Initialize dp[i][j] = 0 for all i ≤ j

       4. for i = 1 to n do

           (a) dp[i][i] = 0    // Base case: single symbols

       5. for len = 2 to n do

           (a) for i = 1 to n − len + 1 do
                  i. j = i + len − 1
                 ii. dp[i][j] = ∞
                iii. for k = i to j − 1 do
                     A. dp[i][j] = min(dp[i][j], 1 + max(dp[i][k], dp[k + 1][j]))

       6. return dp[1][n]


Selectors (views). The only introspective operations are selectors applied to y = ιd (C, n):
VIEW_STATE(y), VIEW_HEAD(y), and VIEW_WIN(y, j) for j ≤ d. Any legacy INT_* names
denote these views.

31.3     Complexity Classes
Definition 31.4 (Psi-P d Class). The class Psi-Pd consists of languages recognizable by Psi-TM
with introspection depth d in polynomial time.

Definition 31.5 (Psi-NP d Class). The class Psi-NPd consists of languages with polynomial-time
verifiable certificates using Psi-TM with introspection depth d.

Definition 31.6 (Psi-PSPACE d Class). The class Psi-PSPACEd consists of languages recognizable
by Psi-TM with introspection depth d using polynomial space.


32      Explicit Language Constructions
32.1     Tree Evaluation Language
Definition 32.1 (Binary Tree Encoding). A binary tree T is encoded as a string encode(T ) ∈ {0, 1}∗
as follows:

  • Each node is encoded as a triple (v, l, r) where v is the node value, l is the left subtree encoding,
    and r is the right subtree encoding

  • Leaf nodes are encoded as (v, ε, ε)

  • The encoding uses a prefix-free code to separate node components



                                                     37
Definition 32.2 (Tree Evaluation Language Lk ). For each k ≥ 1, define Lk as the set of strings
encode(T )#1n where:

  • T is a binary tree of depth exactly k + 1

  • Leaves are labeled with bits

  • Root evaluates to 1 under Boolean logic (AND/OR gates at internal nodes)

Claim 2. For each k ≥ 1 and d := k+1, Lk ∈ Psi-Pd .

Proof. We construct a Psi-TM M with introspection depth k + 1 that recognizes L k in polynomial
time.
   Algorithm:

  1. Parse the input to extract encode(T ) and 1n

  2. Let d := k+1. Obtain y = ιd (C, n) and use selectors over decoded (y) to access the tree structure
     up to depth d

  3. Verify that the tree has depth exactly d

  4. Evaluate the tree bottom-up using the structural information

  5. Accept if and only if the root evaluates to 1

     Time Analysis:

  1. Parsing: O(n)

  2. Depth verification: O(n) using selectors over decodek+1 (y)

  3. Tree evaluation: O(n) since we have complete structural information

  4. Total time: O(n)

     Therefore, Lk ∈ Psi-Pk+1 .


33      Main Result: Strict Hierarchy
Theorem 33.1 (Strict Hierarchy). Assumes the restricted regime (deterministic, single pass, no
advice, no randomness) and uses Table 1. For all d ≥ 1:

                                       Psi-TMd ⊊ Psi-TMd+1

Equivalently:
                                         Psi-Pd ⊊ Psi-Pd+1

Proof. We prove this by showing that for each k ≥ 1, with d := k, the language Lk satisfies:

                                                        / Psi-Pd
                                   Lk ∈ Psi-Pd+1 but Lk ∈

    Membership in Psi-P k+1: This follows from the claim above.
    Non-membership in Psi-P k: We prove that no Psi-TM with introspection depth k can
recognize L k in polynomial time.

                                                 38
Lemma 33.2 (Depth-d Limitation). Assumes the restricted regime (deterministic, single pass, no
advice, no randomness) and uses Table 1. Any Psi-TM with introspection depth d cannot distinguish
between trees of depth d + 1 and trees of depth d in polynomial time.

Proof. Key Insight: Introspection depth d provides access only to patterns of depth ≤ d, but
cannot access depth d + 1 patterns.
   Detailed Proof: For trees T1 (depth d + 1) and T2 (depth d):

  1. Tree Structure Analysis:

       • Both trees have identical node structure up to level d
       • T1 has additional level d + 1 with leaf values
       • T2 terminates at level d with leaf values

  2. Selector Analysis: Decoding y = ιd (C, n) exposes only depth-≤ d tags and values; level d+1
     information is not accessible to selectors.

  3. Selector Equality: Since depth-≤ d features coincide, all selectors over decoded (ιd (C, n))
     return identical values on encode(T1 ) and encode(T2 )

  4. Depth-d agreement: Both inputs share the same depth-d features; therefore selectors agree
     at depth d.

  5. Selector Equality: Since depth-≤ d features coincide, all selectors over decoded (ιd (C, n))
     return identical values on encode(T1 ) and encode(T2 )

  6. Machine Limitation: Machine M with introspection depth d receives identical introspection
     responses for both inputs and therefore cannot distinguish between them.

   Adversary Construction: For any Psi-TM M with introspection depth d, we construct an
adversary A that defeats M :
   Adversary Strategy:

  1. On input w = encode(T )#1n : ensure that for any call y = ιd (C, n), selectors over decoded (y)
     reveal only depth-≤ d features (for depth d+1 inputs, the depth-d projection is revealed).

  2. The adversary ensures that all selectors over decoded (ιd (C, n)) agree on w1 and w2 when one
     has depth d and the other d+1

   Information-Theoretic Argument:

  1. Let T1 be a tree of depth d + 1 and T2 be a tree of depth d

  2. Both trees have identical depth-d structural patterns

  3. The introspection function ιd can only access depth-d information

  4. Therefore, selectors over decoded (ιd (C, n)) cannot distinguish encode(T1 ) from encode(T2 )

  5. Machine M cannot distinguish between these inputs

  6. Since one input is in Lk and the other is not, M must err on at least one input



                                                39
     Separation Proof: By Lemma 33.2, any Psi-TM with introspection depth d must either:

                          / Lk (false positive), or
  1. Accept some input w2 ∈

  2. Reject some input w1 ∈ Lk (false negative)

                              / Psi-Pk .
     This establishes that Lk ∈
                                                      / Psi-Pd , we have:
     Hierarchy Conclusion: Since Lk ∈ Psi-Pd+1 but Lk ∈

                                           Psi-Pd ⊊ Psi-Pd+1

     This holds for all k ≥ 1, establishing the strict hierarchy.


34      Adversary Arguments
34.1     Formal Adversary Construction
Theorem 34.1 (Adversary Lower Bound). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. For any Psi-TM M with introspection depth k,
there exists an adversary A such that: M cannot solve Lk against A.

Proof. We construct an explicit adversary strategy that defeats any depth-k Psi-TM.
   Adversary Strategy:

  1. Input Generation: For each n ≥ 1, the adversary generates two inputs:

         • w1 = encode(T1 )#1n where T1 has depth k + 1 and evaluates to 1
         • w2 = encode(T2 )#1n where T2 has depth k and evaluates to 0

  2. Introspection Response: When M calls INT_PATTERN(k) on input w:

         • If w has depth k: Return actual depth-k patterns
         • If w has depth k + 1: Return only the depth-k projection

  3. Consistency Maintenance: The adversary ensures that: All selectors over decodek (ιk (C, n))
     agree on w1 and w2

     Information-Theoretic Analysis:

  1. The introspection function ιk can only access depth-k information

  2. Both inputs w1 and w2 have identical depth-k structural patterns

  3. Machine M receives identical introspection responses for both inputs

  4. Therefore, M must produce the same output for both inputs

                          / Lk , M must err on at least one input
  5. Since w1 ∈ Lk and w2 ∈

    Error Probability: The adversary can generate inputs such that M errs with probability at
least 1/2 by ensuring that the machine cannot distinguish between valid and invalid inputs based
solely on depth-k information.
    This establishes that no depth-k Psi-TM can solve Lk against this adversary.


                                                    40
35      Complexity Class Implications
35.1     Class Separations
Theorem 35.1 (Complexity Class Separations). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. For all d ≥ 1:

                                  Psi-Pd ⊊ Psi-Pd+1 ⊊ PSPACE

                                Psi-NPd ⊊ Psi-NPd+1 ⊊ NPSPACE
                         Psi-PSPACEd ⊊ Psi-PSPACEd+1 ⊊ EXPSPACE
Proof. Strict Inclusions: Follow from the main hierarchy theorem and the explicit language
constructions.
    PSPACE Inclusions: Any Psi-TM with constant introspection depth can be simulated by
a standard Turing machine with polynomial space overhead, as shown in the formal definition
document.
    Proper Inclusions: The languages Lk demonstrate that the inclusions are proper, as they
belong to higher levels but not to lower levels of the hierarchy.

35.2     Barrier status hierarchy (oracle-relative / conservative)
Theorem 35.2 (Barrier status hierarchy). Assumes the restricted regime (deterministic, single pass,
no advice, no randomness) and uses Table 1. Conservative statements about minimal introspection
depth:
  1. Relativization: k ≥ 1 (proven oracle-relative)

  2. Natural Proofs: k ≥ 2 (partial/conditional)

  3. Proof Complexity: k ≥ 2 (partial/Resolution-only)

  4. Algebraization: k ≥ 3 (open/conservative)
Proof. This follows from the corresponding sections and conservative proofs. In particular:

  1. For k = 1, we have an oracle-relative relativization separation

  2. For k = 2, partial/conditional statements are available for natural proofs and proof complexity

  3. For k = 3, simultaneous bypass is plausible subject to algebraization; unrelativized sufficiency
     open

     This summarizes the conservative barrier status by depth k.


36      Algorithmic Results
36.1     Efficient Simulation
Theorem 36.1 (Efficient Psi-TM Simulation). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. Any Psi-TM Mpsi with d-limited introspection can
be simulated by a standard Turing machine M with slowdown O(n3 · f (d)), where f is a polynomial
function.

                                                 41
Proof. The algorithm is presented below. Each introspection call takes O(n3 ) time by the structural
depth computation algorithm. Total simulation time: O(T (n) · n3 · f (d)).

       Algorithm: Psi-TM Simulation
       1. Initialize state (q0 , ε, ε, ∅)
       2. while not in accepting or rejecting state do
       3. Read current symbol a
       4. Compute y = ιd (C, n) and the needed selectors
       5. Apply transition δ(q, a, ψ) = (q ′ , b, d)
       6. Update configuration
       7. Move head according to d
       8. end while

36.2     Universal Psi-TM
Theorem 36.2 (Existence of Universal Psi-TM). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. There exists a universal Psi-TM Upsi
with d-limited introspection that can simulate any Psi-TM Mpsi with d-limited introspection with
polynomial slowdown.

Proof. We construct Upsi as follows:

  1. Encoding: Upsi takes as input a description of Mpsi and input string x

  2. Simulation: Upsi maintains the configuration of Mpsi on its tape

  3. Introspection: For each introspection call of Mpsi , Upsi computes the same introspection
     using the dynamic programming algorithm

  4. Transitions: Upsi applies the transition function of Mpsi based on the encoded description

   Since both machines have d-limited introspection, the simulation preserves the introspection
constraints. The slowdown is polynomial due to the overhead of interpreting the encoded machine
description and computing introspection calls.


37      Lower Bounds
37.1     Time Complexity Lower Bounds
Theorem 37.1 (Structural Depth Lower Bound). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. For any language L ∈ Psi-Pk+1 \ Psi-Pk ,
there exists a family of inputs {wn }n≥1 such that:

  1. wn has length n

  2. wn requires structural depth k + 1 for recognition

  3. Any Psi-TM with introspection depth k requires Ω(nk+1 ) time to recognize wn

Proof. We construct explicit families of inputs that demonstrate the lower bound.
   Input Family Construction: For each n ≥ 1, construct wn as follows:


                                                42
  1. Start with base pattern P0 = 01
  2. For each level i from 1 to k + 1:
          • Create pattern Pi = Pi−1 ◦ Pi−1 where ◦ represents structural composition
          • Pi has structural depth i
  3. wn = Pk+1 repeated to achieve length n
   Structural Depth Analysis:
  1. P0 has depth 0 (no nested patterns)
  2. P1 = P0 ◦ P0 has depth 1
  3. P2 = P1 ◦ P1 has depth 2
      .
  4. ..
  5. Pk+1 has depth k + 1
   Lower Bound Proof: Any Psi-TM with introspection depth k must:

  1. Pattern Analysis: Process wn by examining depth-k patterns only
  2. Information Limitation: Cannot access the depth k + 1 structural information
  3. Exhaustive Search Requirement: Must check all possible depth-k decompositions

   Complexity Analysis: For trees with n nodes and depth k + 1:

  1. Leaf Count at Level k+1: 2k leaves at level k + 1
                                                                                 k
  2. Possible Configurations: Each leaf can be 0 or 1, giving 22 possible configurations
  3. Tree Size Relationship: For trees with n nodes, 2k = Θ(n1/(k+1) )
                                                           1/(k+1) )
  4. Required Checks: Machine must check 2Θ(n                          possible configurations
  5. Time Complexity: Each check requires Ω(n) time for pattern matching
                               1/(k+1) )
  6. Total Time: Ω(n · 2Θ(n                ) = Ω(nk+1 )

   Formal Justification:
                   Number of leaves at level k + 1 = 2k
                                                             k
                            Possible configurations = 22
                        For trees with n nodes: 2k = Θ(n1/(k+1) )
                                                                 1/(k+1) )
                                   Required checks = 2Θ(n
                                    Time per check = Ω(n)
                                                                         1/(k+1) )
                                             Total time = Ω(n · 2Θ(n                 ) = Ω(nk+1 )
    Upper Bound: A Psi-TM with introspection depth k + 1 can recognize wn in O(n) time by
directly accessing the depth k + 1 pattern.
    This establishes the Ω(nk+1 ) lower bound for depth-k machines.

                                                      43
38     Outlook — Adversary Results
We have established an oracle-relative strict hierarchy of Psi-TM models based on introspection
depth, with the following key points:

  1. Strict Hierarchy (oracle-relative): For each k ≥ 1, Psi-TMk ⊊ Psi-TMk+1 relative to a
     suitable oracle

  2. Explicit Constructions: We provided concrete language constructions Lk that separate each
     level

  3. Adversary Arguments: We constructed formal adversaries that demonstrate the impossibility
     of depth-k machines recognizing depth-(k + 1) languages

  4. Complexity Implications: We established corresponding separations in complexity classes

  5. Barrier Status: k = 3 is a plausible simultaneous target subject to algebraization; unrela-
     tivized sufficiency remains open

    These results provide a rigorous foundation for understanding the relationship between introspec-
tion depth and computational power in the Psi-TM model, opening new directions in computational
complexity theory and formal automata theory.
    The discovery that introspection depth creates a strict computational hierarchy has important
implications for understanding the relationship between self-reflection and computational capability.
This work provides a foundation for future research in introspective computation and opens new
directions in complexity theory.


39     Formal Definitions and Preliminaries
39.1    Structural Pattern Recognition
Definition 39.1 (d-Structural Pattern). For a string w ∈ {0, 1}∗ , the d-structural pattern Pd (w) is
defined recursively:

                       P0 (w) = {individual symbols in w}
                       P1 (w) = P0 (w) ∪ {binary partitions of w}
                       Pd (w) = Pd−1 (w) ∪ {nested structures of depth ≤ d}

Definition 39.2 (Introspective Complexity). The introspective complexity Id (w) of a string w is
the minimum size of description of the d-structural pattern:

                               Id (w) = min{|d| : d describes Pd (w)}

39.2    Formal Introspection Functions
Selectors. Access to structural metadata is via y = ιd (C, n) and selectors over decoded (y) (state,
head, and bounded-depth windows). Legacy INT_* names are aliases to these selectors; no raw
INT_* access is permitted.




                                                 44
40      Information-Theoretic Limitations
Sketch via Lemma 4.1. We recall explicit examples for each d ≥ 1.
   Construction for d = 1: Let w1 = 0011 and w2 = 01.
   Analysis:
  1. d(w1 ) = 2: The optimal parsing tree has structure ((0)(0))((1)(1)) with depth 2
  2. d(w2 ) = 1: The optimal parsing tree has structure (0)(1) with depth 1
  3. All depth-≤ 1 structural features coincide, so selectors over decode1 (ι1 (C, n)) return identical
     values on w1 and w2 (by Lemma 8.2 (Budget Lemma) and Table 1)
     General Construction for d ≥ 2: Let Pd be the pattern of depth d constructed recursively:
  • P0 = 0
  • P1 = 00
  • Pd = Pd−1 ◦ Pd−1 where ◦ represents structural composition
     Let w1 = Pd+1 and w2 = Pd .
     Verification:
  1. d(w1 ) = d + 1 by construction
  2. d(w2 ) = d by construction
  3. Both strings have identical depth-d structural features
  4. Therefore, all selectors over decoded (ιd (C, n)) return identical values on w1 and w2 (by
     Lemma 8.2 (Budget Lemma) and Table 1)



41      Main Theoretical Results
41.1     Complexity Class Hierarchy
Theorem 41.1 (Psi-Class Hierarchy). Assumes the restricted regime (deterministic, single pass, no
advice, no randomness) and uses Table 1. For any d1 < d2 :
                                         Psi-Pd1 ⊆ Psi-Pd2
                                   Psi-PSPACEd1 ⊆ Psi-PSPACEd2
Proof. Let L ∈ Psi-Pd1 . Then there exists a Psi-TM M with d1 -limited introspection that recognizes
L in polynomial time.
   We construct a Psi-TM M ′ with d2 -limited introspection:
  1. M ′ simulates M step-by-step
  2. For each introspection call of M , M ′ performs the same introspection
  3. Since d1 < d2 , all introspection calls of M are valid for M ′
  4. Time complexity remains polynomial
     Thus, L ∈ Psi-Pd2 . The same argument applies to PSPACE classes.

                                                  45
41.2    Connection to Classical Classes
Theorem 41.2 (Inclusion in Classical Classes). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. For any d ≥ 0:
                                         Psi-Pd ⊆ PSPACE
                                   Psi-PSPACEd ⊆ EXPSPACE
Proof. Let L ∈ Psi-Pd . Then there exists a Psi-TM M with d-limited introspection that recognizes
L in polynomial time.
   We construct a standard Turing machine M ′ that simulates M :
  1. State of M ′ encodes (q, α, β, ψ)
  2. Size of ψ is bounded by f (d) · n = O(n) for constant d
  3. Each introspection call is simulated by explicit computation using the dynamic programming
     algorithm
  4. Total space: O(n + f (d) · n) = O(n)
     Thus, L ∈ PSPACE. The EXPSPACE inclusion follows similarly.

41.3    Strict Inclusions
Theorem 41.3 (Strict Inclusions with Minimal Introspection). Assumes the restricted regime
(deterministic, single pass, no advice, no randomness) and uses Table 1. There exist languages L
such that:
                                           L ∈ Psi-P1 \ P
Proof. Consider the Language of Structured Balanced Strings (LSBS ):
    Definition: LSBS = {w ∈ {(, )}∗ : w is balanced and has structural depth ≤ 1}
    Standard TM Complexity: For standard Turing machines, this requires Ω(n2 ) time to track
nesting levels by explicit computation.
    Psi-TM Solution (selectors only): For a depth-1 Psi-TM, in each step obtain y = ι1 (C, n)
and use selectors over decode1 (y) to read a bounded-depth window summary and head position.
Check balance and that the structural depth is ≤ 1 using these selectors.
    Budget accounting: Each call to ι1 has at most 2B(1,n) outcomes; over t = O(n) steps there
are at most 2t·B(1,n) outcome sequences (by Lemma 8.2).
    Formal derivation: By the Budget Lemma, t·B(1, n) = O(n)·c·1·log2 n = O(n log2 n) ≥ log2 M
where M is the number of distinct selector outputs. This ensures the machine has sufficient
information budget to distinguish between valid and invalid inputs.
    Thus, LSBS ∈ Psi-P1 but requires Ω(n2 ) time for standard Turing machines (under standard
complexity assumptions).


42     Algorithmic Results
42.1    Efficient Simulation
Theorem 42.1 (Efficient Psi-TM Simulation). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. Any Psi-TM Mpsi with d-limited introspection can
be simulated by a standard Turing machine M with slowdown O(n3 · f (d)), where f is a polynomial
function.

                                                46
Proof. We present an algorithm for simulating Mpsi :

  Algorithm: Psi-TM Simulation

       1. Initialize state (q0 , ε, ε, ∅)

       2. while not in accepting or rejecting state do

           (a) Read current symbol a
           (b) Compute y = ιd (C, n) and the needed selectors
           (c) Apply transition δ(q, a, ψ) = (q ′ , b, d)
           (d) Update configuration
           (e) Move head according to d

   Each introspection call takes O(n3 ) time by the structural depth computation algorithm. Total
simulation time: O(T (n) · n3 · f (d)).

42.2      Universal Psi-TM
Theorem 42.2 (Existence of Universal Psi-TM). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. There exists a universal Psi-TM Upsi
with d-limited introspection that can simulate any Psi-TM Mpsi with d-limited introspection with
polynomial slowdown.

Proof. We construct Upsi as follows:

  1. Encoding: Upsi takes as input a description of Mpsi and input string x

  2. Simulation: Upsi maintains the configuration of Mpsi on its tape

  3. Introspection: For each introspection call of Mpsi , Upsi computes the same introspection
     using the dynamic programming algorithm

  4. Transitions: Upsi applies the transition function of Mpsi based on the encoded description

   Since both machines have d-limited introspection, the simulation preserves the introspection
constraints. The slowdown is polynomial due to the overhead of interpreting the encoded machine
description and computing introspection calls.


43      Complexity Barriers
43.1      Time bounds (conservative)
Theorem 43.1 (Conservative time statements). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. There exist problems L such that:

  1. L ∈ DTIME(n2 ) for standard Turing machines

  2. L ∈ Psi-Pd for Psi-TM with suitable introspection



                                                      47
Proof. Consider the Structural Matching (SM) problem:
    Definition: Given a string w with nested structures, find all matching pairs at depth ≤ d.
    Standard TM Complexity: For standard Turing machines, this requires Ω(n2 ) time to track
all possible matches by explicit computation.
    Psi-TM Solution (selectors only): For a depth-d Psi-TM, in each relevant step obtain
y = ιd (C, n) and use VIEW_WIN(y, d′ ) for d′ ≤ d to enumerate matching pairs at depth ≤ d.
    Budget accounting: Each ιd call has at most 2B(d,n) outcomes; over t = poly(n) steps there
are at most 2t·B(d,n) sequences (by Lemma 8.2).
    Formal derivation: By the Budget Lemma, t·B(d, n) = poly(n)·c·d·log2 n = poly(n) ≥ log2 M
where M is the number of distinct selector outputs. This ensures sufficient information budget for
pattern matching at depth ≤ d.
    Thus, SM ∈ Psi-Pd but requires Ω(n2 ) time for standard machines.

43.2   Space bounds (conservative)
Theorem 43.2 (Conservative space statements). Assumes the restricted regime (deterministic,
single pass, no advice, no randomness) and uses Table 1. There exist problems L such that:

  1. L ∈ DSPACE(n2 ) for standard Turing machines

  2. L ∈ Psi-PSPACEd for Psi-TM with suitable introspection

Proof. Consider the Structural Analysis (SA) problem:
     Definition: Given a string w with complex nested structures, analyze the structural properties
at all levels.
     Standard TM Complexity: For standard Turing machines, this requires Ω(n2 ) space to store
intermediate structural information.
     Psi-TM Solution (selectors only): For a depth-d Psi-TM, obtain y = ιd (C, n) on demand
and use selectors over decoded (y) to read the required bounded-depth summaries without storing
full intermediate structures.
     Budget accounting: Selectors expose at most B(d, n) bits per call by Lemma 8.2; thus space
needed for introspective data per step is O(B(d, n)).
     Formal derivation: By the Budget Lemma, each selector call exposes at most B(d, n) =
c · d · log2 n = O(log2 n) bits. Over T steps, total space is O(T · log2 n) = O(n log2 n) ≪ O(n2 ),
enabling space-efficient analysis.
     Thus, SA ∈ Psi-PSPACEd but requires Ω(n2 ) space for standard machines.


44     Adversary Arguments
44.1   Formal Adversary Construction
Theorem 44.1 (Adversary Lower Bound). Assumes the restricted regime (deterministic, single
pass, no advice, no randomness) and uses Table 1. For any Psi-TM M with introspection depth d,
there exists an adversary A such that: M cannot solve certain structural problems against A.

Proof. We construct an explicit adversary strategy that defeats any depth-d Psi-TM for specific
problems.
   Adversary Strategy:

  1. Input Generation: For each n ≥ 1, the adversary generates two inputs:


                                                48
        • w1 with structural depth d + 1
        • w2 with structural depth d

  2. Introspection Response: For any call y = ιd (C, n), only depth-≤ d features are exposed via
     selectors over decoded (y); if w has depth d+1, the exposure equals its depth-d projection.

  3. Consistency Maintenance: The adversary ensures that: All selectors over decoded (ιd (C, n))
     agree on w1 and w2

     Information-Theoretic Analysis:

  1. The introspection function ιd can only access depth-d information

  2. Both inputs w1 and w2 have identical depth-d structural patterns

  3. Machine M receives identical introspection responses for both inputs

  4. Therefore, M must produce the same output for both inputs

  5. Since the inputs have different structural properties, M must err on at least one input

   This establishes that no depth-d Psi-TM can solve certain structural problems against this
adversary.


45     Outlook — Theoretical Results
These results provide a rigorous foundation for understanding the computational power of Psi-TM
models with different introspection depths. The key contributions include:

  1. Formal Definitions: Complete formalization of introspection functions and structural patterns

  2. Information-Theoretic Limitations: Explicit constructions showing the limitations of
     depth-d introspection

  3. Complexity Class Hierarchy: Rigorous proofs of class inclusions and separations

  4. Algorithmic Results: Efficient simulation algorithms and universal machine constructions

  5. Barrier Bypassing: Concrete examples of problems where Psi-TM can bypass classical
     complexity barriers

  6. Adversary Arguments: Formal constructions demonstrating the impossibility of certain
     computations

   These results open new directions in computational complexity research and formal automata
theory.

45.1    Controlled Relaxations
We record four relaxations and their explicit polynomial degradations.




                                               49
         Table 3: Controlled Relaxations: Relaxation → Degradation bound → Reference
Relaxation                Degradation bound                                             Reference
R1: Public randomness     explicit in entropy budget H (state dependence on H)          Lemma 45.1
R2: Multi-pass (P passes) P · (m + B(d, n)) ≥ c0 · log M (state origin of c0 )          Lemma 45.1
R3: Advice                survives for o(n) and O(log n); show explicit dependence on   Lemma 45.1
                          |adv|
R4: Bandwidth tweak LB stable under small shifts in B(d, n); bound losses               Lemma 45.1
±O(log n)


Lemma (R1: entropy budget). (lem:R1-entropy-budget) Public randomness with entropy
budget H perturbs the information budget by at most an additive H term. By Budget accounting
and Ψ-Fano/ Ψ-fooling arguments, the lower bound degrades polynomially with explicit dependence
on H in the state space; no change to asymptotic exponents beyond this parameterization.

Lemma (R2: multi-pass). (lem:R2-multipass) For P passes, if P · (m + B(d, n)) ≥ c0 · log M ,
the bound persists with polynomial loss. The constant c0 arises from the query-to-entropy conversion
in the Budget Lemma (normalizing per-step payload to B(d, n) and per-pass overhead m) and the
base-2 encoding used in transcript counting.

Lemma (R3: advice). (lem:R3-advice) With advice |adv| ∈ {O(log n), o(n)}, the lower bound
is stable: the proof augments the information budget by |adv| bits and then applies the Ψ-Fooling/ Ψ-
Fano tool. Dependence on |adv| is explicit and purely additive inside the budget term.

Lemma (R4: bandwidth tweak). (lem:R4-bandwidth-tweak) For bandwidth shifts B(d, n) 7→
B(d, n) ± O(log n), the transcript and budget inequalities change by polylogarithmic factors. Anti-
simulation and budget monotonicity yield that the lower bound is preserved up to polylogarithmic
losses with constants inherited from the corresponding tools.


46     Independent Platforms
46.1    Psi-decision trees
We consider a query model for Psi-machines as decision trees. The depth lower bound obeys
depth ≥ ⌈log2 M/B(d, n)⌉, matching budget constraints.

Lemma 46.1 (DT Lower Bound under R). In the query model (queries reveal at most B(d, n) bits
per step under relaxations R),
                                            log M
                                                  
                               depth ≥               .
                                           B(d, n)
Sketch. Apply the Budget tool: each query contributes at most B(d, n) bits of information. Combine
with Ψ-Fano/ Ψ-fooling to relate distinguishability among M possibilities to total revealed bits. This
yields the inequality; constants follow the transcript encoding used in the tools.

46.2    IC-circuits
We formalize information-constrained (IC) circuits and derive transcript-counting bounds.



                                                  50
  Platform                                 Bound                                     Constants                  ReferenceLemma                                            Notes
  PsiDecisionTree                          ⌈log2 M/B(d, n)⌉                          c0 ; M                     Platform:PsiDecisionTree                                  Query model depth lower bound
  ICGate                                   transcript LB                             α                          Platform:ICGate                                           Transcript counting over IC-gates
  ICAC0                                    IC-AC0 LB                                 c0                         Platform:ICAC0                                            Depth/size tradeoff via transcripts
  ICNC1                                    IC-NC1 LB                                 c0                         Platform:ICNC1                                            Depth/size tradeoff via transcripts


                                                     Table 4: Independent platforms and their lower bounds.


IC-AC0 /IC-NC1 . We use transcript counting with per-gate information constraints.

Lemma 46.2 (IC Transcript Bound). For suitable gate/query budget Q, transcript counting yields
Q · B(k − 1, n) ≥ Ω(n/k). Sketch. Model gate-level observations as bounded-information queries.
Count distinguishable transcripts over input space and equate to required separations; the anti-
simulation and budget tools provide the per-step (per-gate) B(k − 1, n) factor.

Parameter synchronization. Identify {B, T, bw, adv, rand} with circuit parameters: B maps to
per-layer fan-in bound (information per gate), T to depth, bandwidth bw to local wiring/fanin caps,
advice to nonuniform side inputs (advice lines), and randomness to public coins. Thus a DT budget
in Lemma 46.1 transfers to circuit size/depth bounds through Lemma 46.2.


47             Bridges with Explicit Losses
We establish bidirectional transfer principles among Ψ-machines, Ψ-decision trees, and information-
theoretic circuits, tracking polynomial losses in n and explicit polylogarithmic factors in band-
width/advice.

Theorem 47.1 (Bridge: Machine↔Tree). (thm:bridge-machine-tree) Under Controlled
Relaxations R and standard invariants (no out-of-model operations), Ψ-machine parameters
{B, T, bw, adv, rand} transfer to Psi-DT {depth, #queries} with losses bounded by poly(n) and at
most polylog(n) in bandwidth/advice, within domain n ≥ n0 , bw ≤ O(log n), and advice ≤ O(log n)
(or explicitly o(n) where stated). Sketch. Encode a run as a DT transcript with per-query budget
B(d, n) and apply Lemma 46.1. R1 contributes an additive entropy term; R2 aggregates P passes
with constant c0 from the Budget tool; R3 adds explicit |adv| bits; R4 shifts B(d, n) by ±O(log n)
incurring only polylog losses. These yield the stated polynomial/polylogarithmic degradation and the
validity domain.

Theorem 47.2 (Bridge: Tree↔Circuit). (thm:bridge-tree-circuit) Under R and the anti-
simulation hook, Psi-DT bounds transfer to IC-circuits with parameter map {B, T, bw} →
{size, depth, fan-in} and losses bounded by poly(n) (log factors from transcript encoding explicit).
Validity domain as above. Sketch. Use Lemma 46.2 to turn DT query budgets into transcript-counting
constraints for IC circuits. Anti-simulation ensures no super-budget leakage. Log factors arise from
base-2 encoding and layer-wise fan-in aggregation; remaining losses are polynomial from size-depth
normalization.

 Bridge      Source        Target                                 Assumptions                                            Param Map                       LB Ref             UB Ref          Anti-sim Ref                    Validity                           Notes
psi<->dt   Psi-machine      DT         "R1–R4; (under standard invariants with no out-of-model operations)"   "B,T,bw,adv,rand<->depth,queries"     lem:DT-LB-under-R           -                 -         "n>=n0; bw<=O(log n); advice<=O(log n)"   "losses poly + polylog"
dt<->ic        DT        IC-circuits                              "R; anti-sim"                                "depth,queries->size,depth,fan-in"   lem:DT-LB-under-R   lem:IC-transcript   prop:anti-sim              "same as above"                  "explicit log factors"




                                                              Table 6: Bridge equivalences with explicit losses.

                                                                                                                         51
                                      Table 5: Bridge Param Map
 Source                    Target                       Map / Notes
 Ψ{B, T, bw, adv, rand}    DT{depth, #queries}          depth ↔ ⌈log M/B(d, n)⌉; losses: poly + polylog
 DT{depth, #queries}       IC{size, depth, fan-in}      via transcript bound; losses: poly (log factors explicit)


48     Methods
We consolidate the three methodological components: (i) Relaxations, (ii) Platforms, and (iii)
Bridges. Each component exposes explicit parameters and loss accounting that thread through the
main separation.

                                         Bridges with Explicit Losses

                                                 (da )(k c )(log2 n)b+ℓ
                            (da )(log2 n)b                                   (k c )(log2 n)ℓ
     Ψ-Machine                                   Ψ-Decision Tree                                       IC-Circuit




                  Losses are multiplicative; logs are base 2. Composition matches algebraic product.

Figure 6: Separation Stack: tools → relaxations → platforms → bridges. Cross-refs: R1–R4
(Lemmas 45.1–45.1), DT/IC (Lemmas 46.1, 46.2), Bridges (Theorems 47.1, 47.2).

    The cross-references are stable: we cite Table 6 for bridge losses and reuse platform and relaxation
identifiers defined in earlier sections. All logarithms are base 2 (log2 ).

Artifacts & Reproducibility. Repository: Psi-TM. Build: make all (runs checks, Lean
build, and notebooks). Formal status: Lean skeletons build with Lake; IDs synchronized via
paper/claims.yaml. Results and tables under results/ (deterministic seeds). Optionally record
DOI in final camera-ready.


49     Pre-Release Hardening: Stress Tests and Adversarial Outcomes
This appendix summarizes the stress tests, attack families, and outcomes used to harden the Ψ-TM
stack.




                                                   52
49.1    Stress Matrix

  Family               Params                     Pass Region                  Fail Region
  Anti-Sim       B(d, n) = c · d · log2 n       d ≤ 3, single-pass          multi-pass, advice
  Lk UB/LB            k ∈ {2, 3, 4}         UB: O(n), LB: Ω(n/ log2 n)   extra budget factor > 1
  Lphase
   k              transcript collision              UB holds               collision breaks UB
  Sandbox       multi-pass/rand toggles       deterministic, one-pass       stochastic, advice

                               Table 7: Stress matrix and outcomes.

49.2    Notes
All experiments use deterministic seeds (1337). Plots included here are representative; code and full
results are available in the repository.


50     Appendix: Zero-Risk Map
All logarithms use base 2 (log2 ). Deterministic seeds for notebooks are fixed to 1337; generated
outputs are written to results/<DATE>/.... Figures originate from fig/ only.

Scenarios × Outcomes
       Scenario            Premises                     Lemma(s)
       Alt forms agree     Budget + Fooling + Hook      Lk:LB:Main, AntiSim:cor:barrier
       Phase UB aligns     Transcript collision         Lkphase:thm:UB
       Zero-risk CI        Deterministic runs           —


51     Open Problems and Research Directions
51.1    Fractional k values
An open question is whether one can define meaningful introspection for non-integer values of k
(e.g., k = 1.5 or k = π), which would require extending the structural depth concept to non-integers.

51.2    Quantum Psi-TM
How does superposition affect introspection depth? A quantum Psi-TM model could explore whether
quantum parallelism provides additional introspection capabilities or whether the k-constraint
remains fundamental even in quantum computation.

51.3    Average-case complexity
Does the k-hierarchy hold for average-case separations? Understanding whether the minimal
introspection requirements apply to average-case complexity classes would provide insights into the
robustness of our barrier bypass results.




                                                  53
51.4    Circuit complexity extensions
Can the k-hierarchy be extended to circuit models with introspection? This would involve defining
circuit families with bounded introspection depth and analyzing their complexity class relationships.

51.5    Interactive proof systems
How do minimal introspection requirements affect interactive proof systems? Understanding whether
the k-constraint applies to interactive protocols could reveal new connections between introspection
and proof complexity.


52     Conclusion
Psi-TM demonstrates that minimal self-reflection (d = O(1) introspection depth) enables
oracle-relative separation while maintaining computational equivalence to standard Turing
machines. Our result PΨOΨ ̸= N PΨOΨ is oracle-relative. Barrier status is conservative: relativization
(proven oracle-relative), natural proofs and proof complexity (partial/conditional), algebraization
(open/conservative). All introspective accesses are via views over y = ιd (C, n) with per-step payload
bounded by B(d, n) as specified in Table 1.
    The minimality analysis suggests differing introspection requirements under these conservative
assumptions:

   • Relativization requires the lowest introspection depth to bypass (d ≥ 1)

   • Proof Complexity and Natural Proofs require moderate introspection (d ≥ 2)

   • Algebraization: plausible with d ≥ 3 subject to algebraization lower bounds (open)

    It is plausible that d = 3 suffices for simultaneous bypass subject to algebraization; unrelativized
sufficiency remains open.
    The key insight is that even constant-depth structural awareness significantly changes the scope
of complexity-theoretic impossibility results, suggesting new directions for both theoretical computer
science and practical algorithm design.
    Impact: This work opens new research directions in:

   • Complexity theory with bounded introspection

   • Practical algorithms leveraging structural awareness

   • Formal verification of introspective systems

   • Quantum computational models with self-reflection

   • Optimal design principles for introspective computation


References
  [1] S. Aaronson and A. Wigderson. Algebrization: A new barrier in complexity theory. ACM
      Trans. Comput. Theory, 1(1):1–54, 2009.

  [2] S. Arora and B. Barak. Computational Complexity: A Modern Approach. Cambridge University
      Press, 2009.

                                                  54
 [3] L. Babai. Trading group theory for randomness. In Proceedings of STOC, pages 421–429, 1985.

 [4] L. Babai and S. Moran. Arthur-merlin games: A randomized proof system, and a hierarchy of
     complexity classes. J. Comput. Syst. Sci., 36(2):254–276, 1988.

 [5] Theodore Baker, John Gill, and Robert Solovay. Relativizations of the P=?NP question. SIAM
     Journal on Computing, 4(4):431–442, 1975.

 [6] J. L. Balcázar, J. Díaz, and J. Gabarró. Structural Complexity I. Springer, 1988.

 [7] J. L. Balcázar, J. Díaz, and J. Gabarró. Structural Complexity II. Springer, 1990.

 [8] J. L. Balcázar, J. Díaz, and J. Gabarró. Structural Complexity III. Springer, 1992.

 [9] M. Bellare and P. Rogaway. Optimal asymmetric encryption. In Proceedings of EUROCRYPT,
     pages 92–111, 1997.

[10] M. Bellare and P. Rogaway. Introduction to modern cryptography. UCSD Course Notes, 2005.

[11] M. Bellare, R. Canetti, and H. Krawczyk. Keying hash functions for message authentication.
     In Proceedings of CRYPTO, pages 1–15, 1996.

[12] M. Ben-Or, S. Goldwasser, J. Kilian, and A. Wigderson. Multi-prover interactive proofs: How
     to remove intractability assumptions. In Proceedings of STOC, pages 113–131, 1988.

[13] E. Ben-Sasson and A. Wigderson. Short proofs are narrow–resolution made simple. J. ACM,
     48(2):149–169, 2001.

[14] L. Blum, M. Shub, and S. Smale. On a theory of computation and complexity over the real
     numbers: Np-completeness, recursive functions and universal machines. Bull. Amer. Math.
     Soc., 21(1):1–46, 1986.

[15] L. Blum, M. Shub, and S. Smale. On a theory of computation over the real numbers. Notices
     Amer. Math. Soc., 35(1):1–46, 1989.

[16] M. Blum. A machine-independent theory of the complexity of recursive functions. J. ACM, 14
     (2):322–336, 1967.

[17] P. Bürgisser. Completeness and Reduction in Algebraic Complexity Theory. Springer, 2009.

[18] P. Bürgisser, M. Clausen, and M. A. Shokrollahi. Algebraic Complexity Theory. Springer, 1997.

[19] C. S. Calude. Information and Randomness: An Algorithmic Perspective. Springer, 2002.

[20] R. Canetti. Universally composable security: A new paradigm for cryptographic protocols. In
     Proceedings of FOCS, pages 136–145, 2001.

[21] G. J. Chaitin. On the length of programs for computing finite binary sequences. J. ACM, 13
     (4):547–569, 1966.

[22] N. Chomsky. On certain formal properties of grammars. Information and Control, 2(2):
     137–167, 1959.

[23] A. Church. An unsolvable problem of elementary number theory. Amer. J. Math., 58(2):
     345–363, 1936.

                                               55
[24] A. Cobham. The intrinsic computational difficulty of functions. In Proceedings of the 1964
     International Congress for Logic, Methodology and Philosophy of Science, pages 24–30, 1964.

[25] S. A. Cook. The complexity of theorem-proving procedures. Proceedings of STOC, pages
     151–158, 1971.

[26] S. A. Cook and R. A. Reckhow. The relative efficiency of propositional proof systems. J.
     Symbolic Logic, 44(1):36–50, 1979.

[27] Stephen A. Cook and Robert A. Reckhow. The relative efficiency of propositional proof
     systems. Journal of Symbolic Logic, 44(1):36–50, 1979.

[28] F. Cucker and S. Smale. On the mathematical foundations of learning. Bull. Amer. Math.
     Soc., 39(1):1–49, 2002.

[29] R. G. Downey and D. R. Hirschfeldt. Algorithmic Randomness and Complexity. Springer,
     2010.

[30] D. Du and K. Ko. Theory of Computational Complexity. Wiley, 2000.

[31] J. Edmonds. Paths, trees, and flowers. Canad. J. Math., 17:449–467, 1965.

[32] L. Fortnow. The complexity of perfect zero-knowledge. In Proceedings of STOC, pages 204–209,
     1987.

[33] L. Fortnow. Complexity-theoretic aspects of interactive proof systems. PhD thesis, MIT, 1989.

[34] L. Fortnow. The Golden Ticket: P, NP, and the Search for the Impossible. Princeton University
     Press, 2013.

[35] L. Fortnow and S. Homer. A short history of computational complexity. Bull. EATCS, 80:
     95–133, 2003.

[36] L. Fortnow and A. R. Klivans. Efficient learning algorithms yield circuit lower bounds. J.
     Comput. Syst. Sci., 75(1):27–36, 2009.

[37] L. Fortnow and J. Rompel. One-sided versus two-sided error in probabilistic computation. In
     Proceedings of STOC, pages 468–475, 1995.

[38] L. Fortnow and M. Sipser. Are there interactive protocols for co-np languages? Information
     Processing Letters, 28(5):249–251, 1988.

[39] M. R. Garey and D. S. Johnson. Computers and Intractability: A Guide to the Theory of
     NP-Completeness. W. H. Freeman, 1979.

[40] O. Goldreich. Foundations of Cryptography: Basic Tools. Cambridge University Press, 2001.

[41] O. Goldreich. Foundations of Cryptography: Basic Applications. Cambridge University Press,
     2004.

[42] O. Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge University
     Press, 2008.

[43] O. Goldreich, S. Micali, and A. Wigderson. Proofs that yield nothing but their validity or all
     languages in np have zero-knowledge proof systems. J. ACM, 38(3):690–728, 1991.

                                               56
[44] S. Goldwasser and S. Micali. Probabilistic encryption. J. Comput. Syst. Sci., 28(2):270–299,
     1984.

[45] S. Goldwasser, S. Micali, and C. Rackoff. The knowledge complexity of interactive proof
     systems. SIAM J. Comput., 18(1):186–208, 1989.

[46] J. Hartmanis and R. E. Stearns. On the computational complexity of algorithms. Trans. Amer.
     Math. Soc., 117:285–306, 1965.

[47] J. Heintz and M. Sieveking. Lower bounds for polynomials with algebraic coefficients. Theor.
     Comput. Sci., 11(3):321–330, 1980.

[48] J. E. Hopcroft and J. D. Ullman. Formal languages and their relation to automata. Addison-
     Wesley, 1969.

[49] J. E. Hopcroft and J. D. Ullman. Introduction to Automata Theory, Languages, and Computa-
     tion. Addison-Wesley, 1979.

[50] Rafig Huseynzade. Structurally-aware turing machines: Transcending complexity barriers.
     GitHub repository, 2025. URL https://github.com/Acloyer/SA-TM. SA-TM (oracle model)
     preprint on GitHub.

[51] N. Immerman. Nondeterministic space is closed under complementation. SIAM J. Comput.,
     17(5):935–938, 1987.

[52] R. Impagliazzo. A personal view of average-case complexity. Proceedings of STOC, pages
     134–147, 1995.

[53] R. Impagliazzo. Relativized separations of worst-case and average-case complexities. In
     Proceedings of CCC, pages 108–117, 2001.

[54] R. Impagliazzo and A. Wigderson. Derandomizing the polynomial hierarchy if bpp has
     subexponential circuits. In Proceedings of STOC, pages 191–200, 2002.

[55] V. Kabanets and R. Impagliazzo. Derandomizing polynomial identity tests means proving
     circuit lower bounds. In Proceedings of STOC, pages 355–364, 2003.

[56] R. M. Karp. Reducibility among combinatorial problems. In Complexity of Computer
     Computations, pages 85–103, 1972.

[57] R. M. Karp. On the complexity of combinatorial problems: Recent results and new directions.
     In Proceedings of IFIP Congress, pages 1–15, 1974.

[58] R. M. Karp. The probabilistic analysis of some combinatorial search algorithms. In Algorithms
     and Complexity: New Directions and Recent Results, pages 1–19, 1976.

[59] R. M. Karp and M. O. Rabin. Efficient randomized pattern-matching algorithms. IBM J. Res.
     Dev., 31(2):249–260, 1987.

[60] R. M. Karp and V. Ramachandran. Parallel algorithms for shared-memory machines. In
     Handbook of Theoretical Computer Science, pages 869–941, 1990.

[61] R. M. Karp and R. E. Tarjan. Linear expected-time algorithms for connectivity problems. J.
     Algorithms, 8(3):374–381, 1987.

                                               57
[62] R. M. Karp and A. Wigderson. A fast parallel algorithm for the maximal independent set
     problem. J. ACM, 32(4):762–773, 1985.

[63] R. M. Karp, E. Upfal, and A. Wigderson. Constructing a perfect matching is in random nc.
     Combinatorica, 6(1):35–48, 1986.

[64] R. M. Karp, E. Upfal, and A. Wigderson. The complexity of parallel search. J. Comput. Syst.
     Sci., 36(2):225–253, 1988.

[65] J. Katz and Y. Lindell. Introduction to Modern Cryptography. CRC Press, 2014.

[66] S. C. Kleene. Recursive predicates and quantifiers. Trans. Amer. Math. Soc., 53(1):41–73,
     1943.

[67] A. N. Kolmogorov. Three approaches to the quantitative definition of information. Problems
     of Information Transmission, 1(1):1–7, 1965.

[68] D. Kozen. Theory of Computation. Springer, 2006.

[69] R. E. Ladner. On the structure of polynomial time reducibility. J. ACM, 22(1):155–171, 1975.

[70] L. A. Levin. Universal sequential search problems. Problems of Information Transmission, 9
     (3):265–266, 1973.

[71] L. A. Levin. Randomness conservation inequalities; information and independence in mathe-
     matical theories. Information and Control, 61(1):15–37, 1984.

[72] H. R. Lewis and C. H. Papadimitriou. Elements of the Theory of Computation. Prentice-Hall,
     1981.

[73] M. Li and P. M. B. Vitányi. An Introduction to Kolmogorov Complexity and Its Applications.
     Springer, 2008.

[74] C. Lund, L. Fortnow, H. Karloff, and N. Nisan. Algebraic methods for interactive proof
     systems. J. ACM, 39(4):859–868, 1992.

[75] A. A. Markov. On the impossibility of certain algorithms in the theory of associative systems.
     Dokl. Akad. Nauk SSSR, 55(7):583–586, 1947.

[76] P. Martin-Löf. The definition of random sequences. Information and Control, 9(6):602–619,
     1966.

[77] W. S. McCulloch and W. Pitts. A logical calculus of the ideas immanent in nervous activity.
     Bull. Math. Biophys., 5(4):115–133, 1943.

[78] J. Myhill. Finite automata and the representation of events. Technical Report 57–624, WADD
     Technical Report, 1956.

[79] A. Nerode. Linear automaton transformations. Proc. Amer. Math. Soc., 9(4):541–544, 1958.

[80] A. Nies. Computability and Randomness. Oxford University Press, 2009.

[81] C. H. Papadimitriou. Computational Complexity. Addison-Wesley, 1994.



                                               58
 [82] E. L. Post. Recursively enumerable sets of positive integers and their decision problems. Bull.
      Amer. Math. Soc., 50(5):284–316, 1944.

 [83] M. O. Rabin and D. Scott. Finite automata and their decision problems. IBM J. Res. Dev., 3
      (2):114–125, 1959.

 [84] R. Raz. Multilinear-nc1 ̸= nc2 . In FOCS, pages 344–351, 2004.

 [85] Alexander A. Razborov and Steven Rudich. Natural proofs. In Proceedings of the Twenty-
      Eighth Annual ACM Symposium on Theory of Computing (STOC), pages 204–213. ACM,
      1997.

 [86] P. Rogaway. Nonce-based symmetric encryption. In Proceedings of FSE, pages 348–358, 2004.

 [87] R. Saptharishi. A survey of lower bounds in arithmetic circuit complexity. GitHub Survey,
      2014.

 [88] J. E. Savage. Models of Computation: Exploring the Power of Computing. Addison-Wesley,
      1998.

 [89] W. J. Savitch. Relationships between nondeterministic and deterministic tape complexities. J.
      Comput. Syst. Sci., 4(2):177–192, 1970.

 [90] C. P. Schnorr. Process complexity and effective random tests. J. Comput. Syst. Sci., 7(4):
      376–388, 1971.

 [91] A. Shamir. Ip = pspace. J. ACM, 39(4):869–877, 1992.

 [92] C. E. Shannon. A symbolic analysis of relay and switching circuits. Trans. AIEE, 57(12):
      713–723, 1938.

 [93] C. E. Shannon. A mathematical theory of communication. Bell Syst. Tech. J., 27(3):379–423,
      1948.

 [94] C. E. Shannon. The synthesis of two-terminal switching circuits. Bell Syst. Tech. J., 28(1):
      59–98, 1949.

 [95] A. Sherstov. The pattern matrix method. SIAM J. Comput., 40(6):1969–2000, 2011.

 [96] A. Shpilka and A. Yehudayoff. Arithmetic circuits: A survey of recent results and open
      questions. Foundations and Trends in Theoretical Computer Science, 5(3-4):207–388, 2009.

 [97] M. Sipser. Introduction to the Theory of Computation. Cengage Learning, 2012.

 [98] R. J. Solomonoff. A formal theory of inductive inference. Information and Control, 7(1):1–22,
      1964.

 [99] L. J. Stockmeyer. The polynomial-time hierarchy. Theor. Comput. Sci., 3(1):1–22, 1976.

[100] V. Strassen. Vermeidung von divisionen. J. Reine Angew. Math., 264:184–202, 1973.

[101] R. Szelepcsenyi. The method of forcing for nondeterministic automata. Bull. EATCS, 33:
      96–100, 1988.



                                                 59
[102] A. M. Turing. On computable numbers, with an application to the entscheidungsproblem.
      Proc. London Math. Soc., 42(2):230–265, 1936.

[103] L. G. Valiant. Completeness classes in algebra. In Proceedings of STOC, pages 249–261, 1979.

[104] L. G. Valiant. A theory of the learnable. Commun. ACM, 27(11):1134–1142, 1984.

[105] J. von Neumann. First draft of a report on the edvac. IEEE Annals of the History of Computing,
      15(4):27–75, 1945.




                                                60
