{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"../fig\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rng = np.random.default_rng(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper: generate random pointer tables T_j : [m] -> [m] for j=1..k\n",
        "\n",
        "def generate_tables(m: int, k: int, rng: np.random.Generator):\n",
        "    # Each T_j is represented as a length-m array with entries in [0, m-1]\n",
        "    return [rng.integers(low=0, high=m, size=m, dtype=np.int64) for _ in range(k)]\n",
        "\n",
        "\n",
        "def compose_pointer(T_list, s: int):\n",
        "    u = s\n",
        "    for T in T_list:\n",
        "        u = int(T[u])\n",
        "    return u\n",
        "\n",
        "\n",
        "def ceil_log2(m: int) -> int:\n",
        "    return int(np.ceil(np.log2(max(2, m))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "m\talpha_emp\tlog2 M est (bits)\tT_lb_est\n",
            "8\t0.875\t7.00\t0.2500\n",
            "16\t0.875\t14.00\t0.4170\n",
            "32\t0.875\t28.00\t0.7216\n",
            "64\t0.891\t57.00\t1.3009\n",
            "128\t0.898\t115.00\t2.3624\n"
          ]
        }
      ],
      "source": [
        "# Parameters and empirical estimation of fooling family size\n",
        "m_values = [8, 16, 32, 64, 128]\n",
        "k = 5  # depth parameter (k >= 2)\n",
        "c = 1.0  # budget constant\n",
        "alpha_target = 0.9\n",
        "\n",
        "results = []\n",
        "for m in m_values:\n",
        "    # Fix T1..T_{k-1}, vary Tk and b on a large subset S (|S| >= 0.9 m)\n",
        "    T_prefix = generate_tables(m, k-1, rng)\n",
        "    s = int(rng.integers(low=0, high=m))\n",
        "    # Construct S of size floor(0.9 m)\n",
        "    S_size = int(np.floor(0.9 * m))\n",
        "    alpha_emp = S_size / m\n",
        "    # Encoding size: n = k*m*ceil(log2 m) + m\n",
        "    n = k * m * ceil_log2(m) + m\n",
        "    # Empirical proxy for log2 M using last-layer degrees of freedom over S\n",
        "    # M ≈ 2^{alpha*m} => log2 M ≈ alpha*m\n",
        "    log2_M_est = alpha_emp * m\n",
        "    # Lower bound proxy: T ≥ log M / B(k-1,n) with B = c*(k-1)*log2(n)\n",
        "    denom = c * (k - 1) * np.log2(max(2, n))\n",
        "    T_lb_est = log2_M_est / denom\n",
        "    results.append({\n",
        "        'm': m,\n",
        "        'n': n,\n",
        "        'alpha_emp': alpha_emp,\n",
        "        'log2_M_est': log2_M_est,\n",
        "        'T_lb_est': T_lb_est\n",
        "    })\n",
        "\n",
        "# Display a compact table\n",
        "print(\"m\\talpha_emp\\tlog2 M est (bits)\\tT_lb_est\")\n",
        "for r in results:\n",
        "    print(f\"{r['m']}\\t{r['alpha_emp']:.3f}\\t{r['log2_M_est']:.2f}\\t{r['T_lb_est']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:2: SyntaxWarning: invalid escape sequence '\\l'\n",
            "<>:2: SyntaxWarning: invalid escape sequence '\\l'\n",
            "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_40480\\3232417594.py:2: SyntaxWarning: invalid escape sequence '\\l'\n",
            "  We fix $T_1,\\ldots,T_{k-1}$ and vary the last layer $(T_k, b)$ over a large subset $S \\subseteq [m]$ with $|S| \\ge 0.9m$.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nWe fix $T_1,\\\\ldots,T_{k-1}$ and vary the last layer $(T_k, b)$ over a large subset $S \\\\subseteq [m]$ with $|S| \\\\ge 0.9m$.\\nAs a proxy, we take $\\\\log_2 M \\x07pprox \\x07lpha m$ with $\\x07lpha = |S|/m$.\\nThe theoretical lower bound is $T \\\\gtrsim (\\\\log M) / (c (k-1) \\\\log n)$.\\n'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "We fix $T_1,\\ldots,T_{k-1}$ and vary the last layer $(T_k, b)$ over a large subset $S \\subseteq [m]$ with $|S| \\ge 0.9m$.\n",
        "As a proxy, we take $\\log_2 M \\approx \\alpha m$ with $\\alpha = |S|/m$.\n",
        "The theoretical lower bound is $T \\gtrsim (\\log M) / (c (k-1) \\log n)$.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "m=8, alpha_emp=0.875, alpha_line=0.90, T_lb_est=0.2500\n",
            "m=16, alpha_emp=0.875, alpha_line=0.90, T_lb_est=0.4170\n",
            "m=32, alpha_emp=0.875, alpha_line=0.90, T_lb_est=0.7216\n",
            "m=64, alpha_emp=0.891, alpha_line=0.90, T_lb_est=1.3009\n",
            "m=128, alpha_emp=0.898, alpha_line=0.90, T_lb_est=2.3624\n",
            "Saved to: ../paper/fig\\lk_logM.png (162.3 KB)\n"
          ]
        }
      ],
      "source": [
        "# ---- FIX: белый экран / не сохраняется ----\n",
        "import os, sys\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")  # гарантированно неинтерактивный backend\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) чистим всё старое\n",
        "plt.close(\"all\")\n",
        "\n",
        "# 2) убеждаемся, что папка для файлов существует\n",
        "out_dir = \"../fig\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# 3) создаём фигуру и оси с белым фоном\n",
        "fig, ax = plt.subplots(figsize=(10, 6), constrained_layout=True)\n",
        "fig.patch.set_alpha(1.0)\n",
        "fig.patch.set_facecolor(\"white\")\n",
        "ax.set_facecolor(\"white\")\n",
        "\n",
        "# === YOUR PLOT ===\n",
        "# Адаптация исходного кода построения\n",
        "ms = np.array([r['m'] for r in results], dtype=float)\n",
        "log2M = np.array([r['log2_M_est'] for r in results], dtype=float)\n",
        "alpha_emp = np.array([r['alpha_emp'] for r in results], dtype=float)\n",
        "\n",
        "alpha_line = float(alpha_target)\n",
        "\n",
        "ax.plot(ms, log2M, 'o-', label='empirical log2 M ≈ α·m')\n",
        "ax.plot(ms, alpha_line * ms, '--', label=f'theoretical α·m (α={alpha_line:.2f})')\n",
        "ax.set_xlabel('m')\n",
        "ax.set_ylabel('α·m (theoretical)')\n",
        "ax.set_title('Pointer-Chase L_k: α·m vs m')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend()\n",
        "\n",
        "# Report alpha and entropy comparison vs budget\n",
        "for r in results:\n",
        "    n = r['n']\n",
        "    m = r['m']\n",
        "    log2M_emp = r['log2_M_est']\n",
        "    denom = c * (k - 1) * np.log2(max(2, n))\n",
        "    print(f\"m={m}, alpha_emp={r['alpha_emp']:.3f}, alpha_line={alpha_line:.2f}, T_lb_est={log2M_emp/denom:.4f}\")\n",
        "# === /YOUR PLOT ===\n",
        "\n",
        "# 4) проверка, что что-то реально нарисовано\n",
        "has_artists = (len(ax.lines) + len(ax.patches) + len(ax.collections) + len(ax.images)) > 0\n",
        "if not has_artists:\n",
        "    raise RuntimeError(\"На оси ничего не нарисовано. Добавь хотя бы ax.plot(...)/ax.scatter(...).\")\n",
        "\n",
        "# 5) финальный рендер + сохранение (непрозрачный белый фон, «поджать» поля)\n",
        "out_path = os.path.join(out_dir, \"lk_logM.png\")\n",
        "fig.canvas.draw()  # форсируем отрисовку\n",
        "fig.savefig(\n",
        "    out_path,\n",
        "    dpi=300,\n",
        "    bbox_inches=\"tight\",\n",
        "    facecolor=fig.get_facecolor(),\n",
        "    edgecolor=\"none\",\n",
        ")\n",
        "\n",
        "# 6) контроль веса файла\n",
        "size_kb = os.path.getsize(out_path) / 1024\n",
        "print(f\"Saved to: {out_path} ({size_kb:.1f} KB)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "m=8: alpha_emp=0.875, log2M_emp=7.00, theory=7.20\n",
            "m=16: alpha_emp=0.875, log2M_emp=14.00, theory=14.40\n",
            "m=32: alpha_emp=0.875, log2M_emp=28.00, theory=28.80\n",
            "m=64: alpha_emp=0.891, log2M_emp=57.00, theory=57.60\n",
            "m=128: alpha_emp=0.898, log2M_emp=115.00, theory=115.20\n"
          ]
        }
      ],
      "source": [
        "# Entropy analysis: actual vs theoretical α·m bound\n",
        "for r in results:\n",
        "    alpha_emp = r['alpha_emp']\n",
        "    m = r['m']\n",
        "    log2M_emp = r['log2_M_est']\n",
        "    log2M_theory = alpha_target * m\n",
        "    print(f\"m={m}: alpha_emp={alpha_emp:.3f}, log2M_emp={log2M_emp:.2f}, theory={log2M_theory:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
