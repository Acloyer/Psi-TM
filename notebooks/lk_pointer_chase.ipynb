{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rng = np.random.default_rng(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper: generate random pointer tables T_j : [m] -> [m] for j=1..k\n",
        "\n",
        "def generate_tables(m: int, k: int, rng: np.random.Generator):\n",
        "    # Each T_j is represented as a length-m array with entries in [0, m-1]\n",
        "    return [rng.integers(low=0, high=m, size=m, dtype=np.int64) for _ in range(k)]\n",
        "\n",
        "\n",
        "def compose_pointer(T_list, s: int):\n",
        "    u = s\n",
        "    for T in T_list:\n",
        "        u = int(T[u])\n",
        "    return u\n",
        "\n",
        "\n",
        "def ceil_log2(m: int) -> int:\n",
        "    return int(np.ceil(np.log2(max(2, m))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters and empirical estimation of fooling family size\n",
        "m_values = [8, 16, 32, 64, 128]\n",
        "k = 5  # depth parameter (k >= 2)\n",
        "c = 1.0  # budget constant\n",
        "alpha_target = 0.9\n",
        "\n",
        "results = []\n",
        "for m in m_values:\n",
        "    # Fix T1..T_{k-1}, vary Tk and b on a large subset S (|S| >= 0.9 m)\n",
        "    T_prefix = generate_tables(m, k-1, rng)\n",
        "    s = int(rng.integers(low=0, high=m))\n",
        "    # Construct S of size floor(0.9 m)\n",
        "    S_size = int(np.floor(0.9 * m))\n",
        "    alpha_emp = S_size / m\n",
        "    # Encoding size: n = k*m*ceil(log2 m) + m\n",
        "    n = k * m * ceil_log2(m) + m\n",
        "    # Empirical proxy for log2 M using last-layer degrees of freedom over S\n",
        "    # M ≈ 2^{alpha*m} => log2 M ≈ alpha*m\n",
        "    log2_M_est = alpha_emp * m\n",
        "    # Lower bound proxy: T ≥ log M / B(k-1,n) with B = c*(k-1)*log2(n)\n",
        "    denom = c * (k - 1) * np.log2(max(2, n))\n",
        "    T_lb_est = log2_M_est / denom\n",
        "    results.append({\n",
        "        'm': m,\n",
        "        'n': n,\n",
        "        'alpha_emp': alpha_emp,\n",
        "        'log2_M_est': log2_M_est,\n",
        "        'T_lb_est': T_lb_est\n",
        "    })\n",
        "\n",
        "# Display a compact table\n",
        "print(\"m\\talpha_emp\\tlog2 M est (bits)\\tT_lb_est\")\n",
        "for r in results:\n",
        "    print(f\"{r['m']}\\t{r['alpha_emp']:.3f}\\t{r['log2_M_est']:.2f}\\t{r['T_lb_est']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Empirical trend: m (table size) vs log₂ M (distinguishable instances, bits)\n",
        "\n",
        "We fix $T_1,\\ldots,T_{k-1}$ and vary the last layer $(T_k, b)$ over a large subset $S \\subseteq [m]$ with $|S| \\ge 0.9m$. As a proxy, we take $\\log_2 M \\approx \\alpha m$ with $\\alpha = |S|/m$. The theoretical lower bound is $T \\gtrsim (\\log M) / (c (k-1) \\log n)$. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ms = np.array([r['m'] for r in results], dtype=float)\n",
        "log2M = np.array([r['log2_M_est'] for r in results], dtype=float)\n",
        "alpha_emp = np.array([r['alpha_emp'] for r in results], dtype=float)\n",
        "\n",
        "alpha_line = float(alpha_target)  # explicit\n",
        "\n",
        "plt.figure(figsize=(6.4, 4.2))\n",
        "plt.plot(ms, log2M, 'o-', label='empirical log2 M ≈ α·m')\n",
        "plt.plot(ms, alpha_line * ms, '--', label=f'theoretical α·m (α={alpha_line:.2f})')\n",
        "plt.xlabel('m')\n",
        "plt.ylabel('α·m (theoretical)')\n",
        "plt.title('Pointer-Chase L_k: α·m vs m')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "# Save plot directly for paper inclusion\n",
        "plt.savefig('../paper/fig/lk_logM.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Report alpha and entropy comparison vs budget\n",
        "for r in results:\n",
        "    n = r['n']\n",
        "    m = r['m']\n",
        "    log2M_emp = r['log2_M_est']\n",
        "    denom = c * (k - 1) * np.log2(max(2, n))\n",
        "    print(f\"m={m}, alpha_emp={r['alpha_emp']:.3f}, alpha_line={alpha_line:.2f}, T_lb_est={log2M_emp/denom:.4f}\")\n",
        "\n",
        "print('Saved plot to ../paper/fig/lk_logM.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entropy analysis: actual vs theoretical α·m bound\n",
        "for r in results:\n",
        "    alpha_emp = r['alpha_emp']\n",
        "    m = r['m']\n",
        "    log2M_emp = r['log2_M_est']\n",
        "    log2M_theory = alpha_target * m\n",
        "    print(f\"m={m}: alpha_emp={alpha_emp:.3f}, log2M_emp={log2M_emp:.2f}, theory={log2M_theory:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
